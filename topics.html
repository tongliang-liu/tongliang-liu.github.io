<h2><hr><a name="cd"></a>Adversarial Learning</h2>

            <ul>
                 <ol> 
                           <li><p>
                           Removing Adversarial Noise in Class Activation Feature Space [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Removing_Adversarial_Noise_in_Class_Activation_Feature_Space_ICCV_2021_paper.pdf">PDF</A>]<br>
                           D. Zhou, N. Wang, C. Peng, X. Gao, X. Wang, J. Yu, and <b>T. Liu</b><br>
                           In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
                           </p></li>    
                             
                            <li><p>
                            Probabilistic Margins for Instance Reweighting in Adversarial Training. [<A HREF="https://arxiv.org/abs/2106.07904">PDF</A>] <br>
                            Q. Wang, F. Liu, B. Han, <b>T. Liu</b>, C. Gong, G. Niu, M. Zhou, and M. Sugiyama.<br>
                            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                            </p></li>
                             

                           <li><p>
                           Towards Defending against Adversarial Examples via Attack-Invariant Features [<A HREF="https://arxiv.org/pdf/2106.05036.pdf">PDF</A>] <br>
                           D. Zhou, <b>T. Liu</b>, B. Han, N. Wang, C. Peng, and X. Gao <br>
                           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
                           </p></li>            

                           <li><p>
                           Maximum Mean Discrepancy is Aware of Adversarial Attacks [<A HREF="http://proceedings.mlr.press/v139/gao21b/gao21b.pdf">PDF</A>] <br>
                           R. Gao, F. Liu, J. Zhang, B. Han, <b>T. Liu</b>, G. Niu, M. Sugiyama <br>
                           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
                           </p></li>


                           <li><p>
                           Learning Diverse-Structured Networks for Adversarial Robustness [<A HREF="https://arxiv.org/pdf/2102.01886.pdf">PDF</A>] <br>
                           X. Du, J. Zhang, B. Han, <b>T. Liu</b>, Y. Rong, G. Niu, J. Huang, and M. Sugiyama <br>
                           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
                           </p></li>
                             
                             
                            <li><p>
                            Dual-Path Distillation: A Unified Framework to Improve Black-Box Attacks. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Paper.pdf">PDF</A>]<br>
                            Y. Zhang, Y. Li, <b>T. Liu</b>, and X. Tian.<br>
                             In <a href="https://icml.cc/"> ICML</a>, 2020.
                            </p></li>
                             
                </ol>
            </ul>
                  

<h2><hr><a name="cd"></a>Learning with Noisy Labels</h2>

            <ul>
                 <ol> 
                


                     
                <li><p>
                Understanding and Improving Early Stopping for Learning with Noisy Labels. [<A HREF="https://arxiv.org/abs/2106.15853">PDF</A>] <br>
                Y, Bai, E. Yang, B. Han, Y. Yang, J. Li, Y. Mao, G. Niu, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                     
               <li><p>
               Me-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Bai_Me-Momentum_Extracting_Hard_Confident_Examples_From_Noisily_Labeled_Data_ICCV_2021_paper.pdf">PDF</A>] [<font color="red">Oral</font>]<br>
               Y. Bai and <b>T. Liu</b><br>
               In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
               </p></li>           
               

                <li><p>
                Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] <br>
                Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                

                         
                
               <li><p>
               A Second-Order Approach to Learning with Instance-Dependent Label Noise. [<A HREF="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.pdf">PDF</A>] [<font color="red">Oral</font>] <br>
               Z. Zhu, <b>T. Liu</b>, and Y. Liu.<br>
               In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
               </p></li>

                
                <li><p>
               Confidence Scores Make Instance-dependent Label-noise Learning Possible [<a href="http://proceedings.mlr.press/v139/berthon21a/berthon21a.pdf">PDF</a>] [<font color="red">Long Talk</font>] <br>
               A. Berthon, B. Han, G. Niu, <b>T. Liu</b>, and M. Sugiyama <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>
               
               <li><p>
               Provably End-to-end Label-noise Learning without Anchor Points [<A HREF="https://arxiv.org/pdf/2102.02400.pdf">PDF</A>] <br>
               X. Li, <b>T. Liu</b>, B. Han, G. Niu, and M. Sugiyama<br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>           
                
               <li><p>
               Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels [<A HREF="http://proceedings.mlr.press/v139/wu21f/wu21f.pdf">PDF</A>] <br>
               S. Wu*, X. Xia*, <b>T. Liu</b>, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>

                
 
               <li><p>
               Robust early-learning: Hindering the memorization of noisy labels. [<A HREF="https://openreview.net/forum?id=Eql5b1_hTE4">PDF</A>]  <br>
               X. Xia, <b>T. Liu</b>, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2021.
               </p></li>



               <li><p>
               Learning with Group Noise. [<A HREF="https://arxiv.org/abs/2103.09468">PDF</A>]<br>
               Q. Wang, J. Yao, C. Gong, <b>T. Liu</b>, M. Gong, H. Yang, and B. Han.<br>
               In <a href="https://aaai.org/Conferences/AAAI-21/"> AAAI</a>, 2021.
               </p></li>

               <li><p>
               Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. [<A HREF="https://arxiv.org/abs/2101.05467">PDF</A>] <br>
               Q. Wang, B. Han, <b>T. Liu</b>, G. Niu, J. Yang, and C. Gong.<br>
               In <a href="https://aaai.org/Conferences/AAAI-21/"> AAAI</a>, 2021.
               </p></li>
                
                
                <li><p>
                Part-dependent Label Noise: Towards Instance-dependent Label Noise. [<A HREF="https://arxiv.org/abs/2006.07836">PDF</A>] [<font color="red">Spotlight</font>]<br>
                X. Xia, <b>T. Liu</b>, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                </p></li>
                
                            
                <li><p>
                Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. [<A HREF="https://arxiv.org/abs/2006.07805">PDF</A>] <br>
                Y. Yao, <b>T. Liu</b>,  B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                </p></li>
                

                
                
                <li><p>
                Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces. [<A HREF="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560715.pdf">PDF</A>] <br>
                J. Deng, J. Guo, <b>T. Liu</b>, M. Gong, and S Zafeiriou.<br>
                In <a href="https://eccv2020.eu/"> ECCV</a>, 2020.
                </p></li>
                
                

                
                
                <li><p>
                Learning with Bounded Instance- and Label-dependent Label Noise. [<A HREF="https://arxiv.org/abs/1709.03768">PDF</A>] <br>
                J. Cheng, <b>T. Liu</b>, K. Rao, and D. Tao.<br>
                In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>
                


                <li><p>
                Label-Noise Robust Domain Adaptation. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1942-Paper.pdf">PDF</A>]<br>
                X. Yu, <b>T. Liu</b>, M. Gong, K. Zhang, K. Batmanghelich, and D. Tao.<br>
                 In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>



               
                <li><p>
                Generative-Discriminative Complementary Learning. [<A HREF="https://kayhan.dbmi.pitt.edu/sites/default/files/AAAI_complementary_learning_v4.pdf">PDF</A>] <br>
                Y. Xu, M. Gong, J. Chen, <b>T. Liu</b>, K. Zhang, and K. Batmanghelich.<br>
                In <a href="http://www.aaai.org/Conferences/AAAI/aaai20.php"> AAAI</a>, 2020.
                </p></li>

                


                <li><p>
                Are Anchor Points Really Indispensable in Label-Noise Learning? [<A HREF="https://arxiv.org/abs/1906.00189">PDF</A>]<br>
                X. Xia, <b>T. Liu</b>, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
                In <a href="https://nips.cc/">NeurIPS</a>, 2019.
                </p></li>
                


                <li><p>
                DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs. [<A HREF="https://arxiv.org/pdf/1905.03465.pdf">PDF</A>]  <br>
                E. Yang, <b>T. Liu</b>, C. Deng, W. Liu, and D. Tao.<br>
                In <a href="http://cvpr2019.thecvf.com/">CVPR</a></i>, 2019.
                </p></li>


                
                <li><p>
                Positive and Unlabeled Learning with Label Disambiguation. [<A HREF="https://www.ijcai.org/Proceedings/2019/0590.pdf">PDF</A>]<br>
                C. Zhang, D. Ren, <b>T. Liu</b>, J. Yang, and C. Gong.<br>
                In <a href="https://ijcai-19.org/"> IJCAI</a>, 2019.
                </p></li>



                <li><p>
                An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption. [<A HREF="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_An_Efficient_and_CVPR_2018_paper.pdf">PDF</A>] <br>
                X. Yu, <b>T. Liu</b>, M. Gong, K. Batmanghelich, and D. Tao.<br>
                In <a href="http://cvpr2018.thecvf.com/">CVPR</a></i>, 2018.
                </p></li>


                <li><p>
                Learning with Biased Complementary Labels. [<A HREF="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdf">PDF</A>] [<font color="red">Oral</font>]<br>
                X. Yu, <b>T. Liu</b>, M. Gong, and D. Tao.<br>
                In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                </p></li>

<!--             <li><p>
            LR-SVM+: Learning Using Privileged Information with Noisy Labels. [<A HREF="https://ieeexplore.ieee.org/document/9556575">Paper</A>]<br>
            Z. Wu, X. Xia, R. Wang, J. Li, J. Yu, Y. Mao, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, accepted.<br/>
            </p></li>

            <li><p>
            Trustable Co-label Learning from Multiple Noisy Annotators. <br>
            S. Li, <b>T. Liu</b>, J. Tan, D. Zeng, and S. Ge.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, accepted.<br/>
            </p></li>    -->

            <li><p>
            Instance-Dependent Positive and Unlabeled Learning with Labeling Bias Estimation. [<A HREF="https://ieeexplore.ieee.org/document/9361303">Paper</A>]<br>
            C. Gong, Q. Wang, <b>T. Liu</b>, B. Han, J. You, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
            </p></li>     

            <li><p>
            Loss Decomposition and Centroid Estimation for Positive and Unlabeled Learning. [<A HREF="https://ieeexplore.ieee.org/document/8839365">Paper</A>]<br>
            C. Gong, H. Shi, <b>T. Liu</b>, C. Zhang, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 43(3): 918-932, 2021.<br/>
            </p></li>

<!--             <li><p>
            Harnessing Side Information for Classification under Label Noise. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8848850">Paper</A>]<br>
            Y. Wei, C. Gong, S. Chen, <b>T. Liu</b>, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(9): 3178-3192, 2020.<br/>
            </p></li>

            <li><p>
            Multi-class Learning with Partially Corrupted Labels. [<A HREF="https://ieeexplore.ieee.org/document/7929355">Paper</A>]<br>
            R. Wang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 29(6): 2568-2580, 2018.<br/>
            </p></li> -->

<!--             <li><p>
            A Regularization Approach for Instance-Based Superset Label Learning. [<A HREF="https://arxiv.org/pdf/1904.02832.pdf">PDF</A>]  <br>
            C. Gong, <b>T. Liu</b>, Y. Tang, J. Yang, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IEEE T-CYB</a></i>, 48(3): 967-978, 2018.<br/>
            </p></li>
 -->
            <li><p>
            Classification with Noisy Labels by Importance Reweighting. [<A HREF="https://arxiv.org/pdf/1411.7718.pdf">PDF</A>] <br>
            <b>T. Liu</b> and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 38(3): 447-461, 2016.<br/>
            </p></li>
                


             </ol>
            </ul>

    
                     
<h2><hr><a name="cd"></a>Transfer Learning</h2>
            <ul>
                 <ol> 
                            <li><p>
                            Confident-Anchor-Induced Multi-Source-Free Domain Adaptation. [<A HREF="https://papers.nips.cc/paper/2021/file/168908dd3227b8358eababa07fcaf091-Paper.pdf">PDF</A>]<br>
                            J. Dong, Z. Fang, A. Liu, G. Sun, and <b>T. Liu</b>.<br>
                            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                            </p></li>
                             
                            <li><p>
                            TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation. [<A HREF="https://arxiv.org/abs/2106.06326">PDF</A>] [<font color="red">Spotlight</font>]<br>
                            H. Chi, F. Liu, W. Yang, L. Lan, <b>T. Liu</b>, B. Han, W. Cheung, and J. Kwok.<br>
                            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                            </p></li>
                             
                             
                            <li><p>
                            Domain Generalization via Entropy Regularization. [<A HREF="https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf">PDF</A>] <br>
                            S. Zhao, M. Gong, <b>T. Liu</b>,  H. Fu, and D. Tao.<br>
                            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                            </p></li>
                             

                             
                            <li><p>
                            LTF: A Label Transformation Framework for Correcting Label Shift. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf">PDF</A>] <br>
                            J. Guo, M. Gong, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
                             In <a href="https://icml.cc/"> ICML</a>, 2020.
                            </p></li>

                            <li><p>
                            Deep Heterogeneous Multi-Task Metric Learning for Visual Recognition and Retrieval. [<A HREF="https://dl.acm.org/doi/10.1145/3394171.3413574">Paper</A>]<br>
                            S. Gan, Y. Luo, Y. Wen, <b>T. Liu</b>, and H. Hu.<br>
                            In <a href="https://2020.acmmm.org/"> ACM MM</a>, 2020. <br>
                            </p></li>
                             
                            <li><p>
                            Towards Digital Retina in Smart Cities: A Model Generation, Utilization and Communication Paradigm. [<A HREF="https://arxiv.org/pdf/1907.13368.pdf">PDF</A>] [<font color="red">Best Paper Award</font>]  <br>
                            Y. Lou, L. Duan, Y. Luo, Z. Chen, <b>T. Liu</b>, S. Wang, and W. Gao.<br>
                            In <a href="http://www.icme2019.org/"> ICME</a>, 2019.
                            </p></li>
                             
                            <li><p>
                            Correcting the Triplet Selection Bias for Triplet Loss. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Baosheng_Yu_Correcting_the_Triplet_ECCV_2018_paper.pdf">PDF</A>]<br>
                            B. Yu, <b>T. Liu</b>, M. Gong, C. Ding, and D. Tao.<br>
                            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                            </p></li>

                            <li><p>
                            Deep Domain Generalization via Conditional Invariant Adversarial Networks. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ya_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdf">PDF</A>] [<font color="red">Oral</font>]<br>
                            Y. Li, X. Tian, M. Gong, Y. Liu, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
                            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                            </p></li>

                            <li><p>
                            Online Heterogeneous Transfer Metric Learning. [<A HREF="https://www.ijcai.org/proceedings/2018/0350.pdf">PDF</A>]<br>
                            Y. Luo, <b>T. Liu</b>, Y. Wen, and D. Tao.<br>
                            In <a href="https://ijcai-18.org/">IJCAI</a>, 2018.
                            </p></li>

                            <li><p>
                            Domain Generalization via Conditional Invariant Representations. [<A HREF="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16595">PDF</A>]<br>
                            Y. Li, M. Gong, X. Tian, <b>T. Liu</b>, and D. Tao.<br>
                            In <a href="http://www.aaai.org/Conferences/AAAI/aaai18.php"> AAAI</a>, 2018
                            </p></li>
                             
                            <li><p>
                            On Compressing Deep Models by Low Rank and Sparse Decomposition. [<A HREF="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_On_Compressing_Deep_CVPR_2017_paper.pdf">PDF</A>]  [<font color="red">Spotlight</font>]<br>
                            X. Yu, <b>T. Liu</b>, X. Wang, and D. Tao.<br>
                            In <a href="http://cvpr2017.thecvf.com/"> CVPR</a>, 2017.
                            </p></li>

                            <li><p>
                            Understanding How Feature Structure Transfers in Transfer Learning. [<A HREF="https://www.ijcai.org/Proceedings/2017/0329.pdf">PDF</A>]<br>
                            <b>T. Liu</b>, Q. Yang, and D. Tao.<br>
                            In <a href="https://ijcai-17.org/"> IJCAI</a>, 2017.
                            </p></li>

                            <li><p>
                            General Heterogeneous Transfer Distance Metric Learning via Knowledge Fragments Transfer.  [<font color="red">Best Paper Award candidate</font>] [<A HREF="https://www.ijcai.org/Proceedings/2017/0341.pdf">PDF</A>]<br>
                            Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
                            In <a href="https://ijcai-17.org/"> IJCAI</a></i>, 2017.
                            </p></li>

                            <li><p>
                            Domain Adaptation with Conditional Transferable Components. [<A HREF="http://proceedings.mlr.press/v48/gong16.pdf">PDF</A>] <br>
                            M. Gong, K. Zhang, <b>T. Liu</b>, D. Tao, C. Glymour, and B. Schölkopf.<br>
                            In <a href="http://icml.cc/2016/"> ICML</a></i>, 2016.
                            </p></li>

                            <li><p>
                            Multi-Task Model and Feature Joint Learning. [<A HREF="https://www.ijcai.org/Proceedings/15/Papers/512.pdf">PDF</A>] <br>
                            Y. Li, X. Tian, <b>T. Liu</b>, and D. Tao.<br>
                            In <a href="http://ijcai-15.org/"> IJCAI</a>, 2015.
                            </p></li>

                        <li><p>
                        Bridging the Gap between Few-Shot and Many-Shot Learning via Distribution Calibration. [<A HREF="https://ieeexplore.ieee.org/document/9634045">Paper</A>]<br>
                        S. Yang, S. Wu, <b>T. Liu</b>, and M. Xu.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
                        </p></li>     

                        <li><p>
                        Transferable Coupled Network for Zero-Shot Sketch-Based Image Retrieval. [<A HREF="https://ieeexplore.ieee.org/document/9591307">Paper</A>]<br>
                        H. Wang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
                        </p></li>     


                        <li><p>
                        Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation.[<A HREF="https://ieeexplore.ieee.org/document/9204804">Paper</A>]<br>
                        X. Yang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
                        </p></li>            



                        <li><p>
                        Transferring Knowledge Fragments for Learning Distance Metric from A Heterogeneous Domain. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8333749">Paper</A>] <br>
                        Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(4): 1013-1026, 2019.<br/>
                        </p></li>


                </ol>
            </ul>

<h2><hr><a name="cd"></a>Unsupervised Learning</h2>
            <ul>
                 <ol> 
                            <li><p>
                            Diversified Bayesian Nonnegative Matrix Factorization. [<A HREF="https://www.aaai.org/Papers/AAAI/2020GB/AAAI-QiaoM.5577.pdf">PDF</A>]<br>
                            M. Qiao, J. Yu, <b>T. Liu</b>, X. Wang, and D. Tao.<br>
                            In <a href="http://www.aaai.org/Conferences/AAAI/aaai20.php"> AAAI</a>, 2020.
                            </p></li>    
                             
                             
                            <li><p>
                            Quantum Divide-and-Conquer Anchoring for Separable Non-negative Matrix Factorization. [<A HREF="https://www.ijcai.org/proceedings/2018/0289.pdf">PDF</A>]<br>
                            Y. Du, <b>T. Liu</b>, Y. Li, R. Duan, and D. Tao.<br>
                            In <a href="https://ijcai-18.org/">IJCAI</a>, 2018.
                            </p></li>

                            <li><p>
                            Semantic Structure-based Unsupervised Deep Hashing. [<A HREF="https://www.ijcai.org/proceedings/2018/0148.pdf">PDF</A>]<br>
                            E. Yang, C. Deng, <b>T. Liu</b>, W. Liu, and D. Tao.<br>
                            In <a href="https://ijcai-18.org/"> IJCAI</a>, 2018.
                            </p></li>  

                            <li><p>
                            Spectral Ensemble Clustering.  <br>
                            H. Liu*, <b>T. Liu</b>*, J. Wu, D. Tao, and Y. Fu. [<A HREF="https://dl.acm.org/doi/10.1145/2783258.2783287">Paper</A>]<br>
                            In <a href="http://www.kdd.org/kdd2015/">KDD</a>, 2015.<br>
                            </p></li>
                             

                        <li><p>
                        Absent Multiple Kernel Learning Algorithms. [<A HREF="https://ieeexplore.ieee.org/document/8627941">Paper</A>]<br>
                        X. Liu, L. Wang, X. Zhu, M. Li, E. Zhu, <b>T. Liu</b>, L. Liu, Y. Dou, and J. Yin.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 42(6): 1303-1316, 2020.<br/>
                        </p></li>



                        <li><p>
                        Multiple Kernel k-means with Incomplete Kernels. [<A HREF="https://ieeexplore.ieee.org/document/8611131">Paper</A>]<br>
                        X. Liu, X. Zhu, M. Li, L. Wang, E. Zhu, <b>T. Liu</b>, M. Kloft, D. Shen, J. Yin, and W. Gao. <br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 42(5): 1191-1204, 2020.<br/>
                        </p></li>

                        <li><p>
                        Truncated Cauchy Non-negative Matrix Factorization. [<A HREF="https://arxiv.org/abs/1906.00495">PDF</A>]<br>
                        N. Guan*, <b>T. Liu</b>*, Y. Zhang, D. Tao, and L. S. Davis.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(1): 246-259, 2019.<br/>
                        </p></li>  


 
                </ol>
            </ul>



<h2><hr><a name="cd"></a>Statistical (Deep) Learning Theory</h2>
            <ul>
                 <ol> 
                            <li><p>
                            Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence. [<A HREF="https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf">PDF</A>]<br>
                            F. He, <b>T. Liu</b>, and D. Tao.<br>
                            In <a href="https://nips.cc/">NeurIPS</a></i>, 2019.
                            </p></li>   

                            <li><p>
                            Skipping Two Layers in ResNet Makes the Generalization Gap Smaller than Skipping One or No Layer. [<A HREF="https://link.springer.com/chapter/10.1007/978-3-030-16841-4_36">Paper</A>]<br>
                            Y. Furusho, <b>T. Liu</b>, and K. Ikeda.<br>
                            In <a href="https://innsbddl2019.org/"> INNSBDDL</a>, 2019. <br>
                            </p></li>

                            <li><p>
                            Algorithmic Stability and Hypothesis Complexity. [<A HREF="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">PDF</A>]<br>
                            <b>T. Liu</b>, G. Lugosi, G. Neu and D. Tao.<br>
                            In <a href="https://2017.icml.cc/"> ICML </a>, 2017.
                            </p></li>

                            <li><p>
                            On the Robustness and Generalization of Cauchy Regression. [<font color="red">Best Paper Award</font>][<A HREF="https://ieeexplore.ieee.org/document/6920341">Paper</A>] <br>
                            <b>T. Liu</b> and D. Tao.<br>
                            In <a href="http://web.siat.ac.cn/icist2014/"> ICIST</a>, 2014.<br>
                            </p></li>

                        <li><p>
                        An Optimal Transport Analysis on Generalization in Deep Learning. [<A HREF="https://ieeexplore.ieee.org/document/9546990">Paper</A>]<br>
                        J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, accepted.<br/>
                        </p></li>

                        <li><p>
                        On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes Optimal Classifier. [<A HREF="https://arxiv.org/pdf/1802.03688.pdf">Paper</A>]<br>
                        J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, accepted.<br/>
                        </p></li>

                        <li><p>
                        Orthogonal Deep Neural Networks.<br>
                        K. Jia, S. Li, Y. Wen, <b>T. Liu</b>, and D. Tao. [<A HREF="https://arxiv.org/abs/1905.0592">PDF</A>] <br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 43(4): 1352-1368, 2021.<br/>
                        </p></li>

                        <li><p>
                        Why ResNet Works? Residuals Generalize. [<A HREF="https://arxiv.org/abs/1904.01367">PDF</A>]<br>
                        F. He, <b>T. Liu</b>, and D. Tao.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(12): 5349-5362, 2020.<br/>
                        </p></li>

                        <li><p>
                        Algorithm-Dependent Generalization Bounds for Multi-Task Learning. [<A HREF="https://ieeexplore.ieee.org/document/7437460">Paper</A>]<br>
                        <b>T. Liu</b>, D. Tao, M. Song, and S. J. Maybank.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 39(2): 227-241, 2017.<br/>
                        </p></li>

                        <li><p>
                        Dimensionality-Dependent Generalization Bounds for k-Dimensional Coding Schemes.</font> [<A HREF="https://arxiv.org/pdf/1601.00238.pdf">PDF</A>] <br>
                        <b>T. Liu</b>, D. Tao, and D. Xu.<br>
                        <i><a target="_blank" href="http://www.mitpressjournals.org/loi/neco">NECO</a></i>, 28(10): 2213-2249, 2016.<br/>
                        </p></li>

                        <li><p>
                        On the Performance of MahNMF Manhattan Non-negative Matrix Factorization. [<A HREF="https://ieeexplore.ieee.org/document/7192641">Paper</A>]<br>
                        <b>T. Liu</b> and D. Tao.<br>
                        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 27(9): 1851-1863, 2016.<br/>
                        </p></li>

                </ol>
            </ul>



