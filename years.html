

            <ul >
<!--                <ol reversed>  -->
               <ol > 
                           <br>
<h2><a name="cd"></a>Major conference papers (fully reviewed)</h2>

                           
                        <li><p>
                        Learning the Latent Causal Structure for Modeling Label Noise. <br>
                        Y. Lin, Y. Yao, and <b>T. Liu</b>.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                           
                        <li><p>
                        NoiseGPT: Label Noise Detection and Rectification through Probability Curvature. <br>
                        H. Wang, Z. Huang, Z. Lin, and <b>T. Liu</b>.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                        <li><p>
                        Few-Shot Adversarial Prompt Learning on Vision-Language Models. <br>
                        Y. Zhou, X. Xia, Z. Lin, B. Han, and <b>T. Liu</b>.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li>

                           
                        <li><p>
                        What If the Input is Expanded in OOD Detection? <br>
                        B. Zhang, J. Zhu, Z. Wang, <b>T. Liu</b>, B. Du, and B. Han.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 


                        <li><p>
                        In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment. <br>
                        D. Hu, H. Fu, J. Guo, L. Peng, T. Chu, F. Liu, <b>T. Liu</b>, and M. Gong.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                        <li><p>
                        Mind the Gap Between Prototypes and Images in Cross-domain Finetuning. <br>
                        H. Tian, F. Liu, Z. Zhou, <b>T. Liu</b>, C. Zhang, and B. Han.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 



                        <li><p>
                        Discovery of the Hidden World with Large Language Models. <br>
                        C. Liu, Y. Chen, <b>T. Liu</b>, M. Gong, J. Cheng, B. Han, and K. Zhang.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                        <li><p>
                        Pseudo-Private Data Guided Model Inversion Attacks. <br>
                        X. Peng, B. Han, F. Liu, <b>T. Liu</b>, and M. Zhou.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                        <li><p>
                        Unveiling Causal Reasoning in Large Language Models: Reality or Mirage? <br>
                        H. Chi, H. Li, W. Yang, F. Liu, L. Lan, X. Ren, <b>T. Liu</b>, and B. Han.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 


                        <li><p>
                        Decomposed Prompt Decision Transformer for Efficient Unseen Task Generalization. <br>
                        H. Zheng, L. Shen, Y. Luo, <b>T. Liu</b>, J. Shen, and D. Tao.<br>
                        In <a href="https://nips.cc/Conferences/2024"> NeurIPS</a>, 2024.
                        </p></li> 

                        <li><p>
                        Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints. [<font color="red">Spotlight</font>]   <br>        
                        X. Xia, J. Liu, S. Zhang, Q. Wu, H. Wei, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li>                         
                        
                        <li><p>
                        Improving Accuracy-robustness Trade-off via Pixel Reweighted Adversarial Training. <br>        
                        J. Zhang, F. Liu, D. Zhou, J. Zhang, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Unraveling the Impact of Heterophilic Structures on Graph Positive-Unlabeled Learning. <br>        
                        Y. Wu, J. Yao, B. Han, L. Yao, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Mitigating Label Noise on Graphs via Topological Sample Selection. <br>        
                        Y. Wu, J. Yao, X. Xia, J. Yu, R. Wang, B. Han, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 


                        <li><p>
                        Layer-Aware Analysis of Catastrophic Overfitting: Revealing the Pseudo-Robust Shortcut Dependency. <br>        
                        R. Lin, C. Yu, B. Han, H. Su, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Towards Realistic Model Selection for Semi-supervised Learning. <br>        
                        M. Li, X. Xia, R. Wu, F. Huang, J. Yu, B. Han, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Machine Vision Therapy: Multimodal Large Language Models Can Enhance Visual Robustness via Denoising In-Context Learning. <br>        
                        Z. Huang, C. Liu, Y. Dong, H. Su, S. Zheng, and <b>T. Liu</b>.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Task-aware Orthogonal Sparse Network for Exploring Shared Knowledge in Continual Learning. <br>        
                        Y. Hu, D. Cheng, D. Zhang, N. Wang, <b>T. Liu</b>, and X. Gao.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection. <br>        
                        C. Cao, Z. Zhong, Z. Zhou, Y. Liu, <b>T. Liu</b>, and B. Han.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 

                        <li><p>
                        MOKD: Cross-domain Finetuning for Few-shot Classification via Maximizing Optimized Kernel Dependence. <br>        
                        H. Tian, F. Liu, <b>T. Liu</b>, B. Du, Y. Cheung, B. Han.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 



                        <li><p>
                        Optimal Kernel Choice for Score Function-based Causal Discovery. <br>        
                        W. Wang, B. Wang, F. Liu, X. You, <b>T. Liu</b>, K. Zhang, and M. Gong.<br> 
                        In <a href="https://icml.cc/Conferences/2024"> ICML</a>, 2024.
                        </p></li> 


                        <li><p>
                        One-Shot Learning as Instruction Data Prospector for Large Language Models. <br>        
                        Y. Li, B. Hui, X. Xia, J. Yang, M. Yang, L. Zhang, S. Si, L. Chen, J. Liu, <b>T. Liu</b>, F. Huang, and Y. Li.<br> 
                        In <a href="https://2024.aclweb.org/"> ACL</a>, 2024.
                        </p></li> 

                           
                        <li><p>
                        Transferability Barrier is Fragile: Free-Lunch for Transferring the Non-Transferable Learning. [<font color="red">Highlight</font>]   <br>        
                        Z. Hong, L. Shen, and <b>T. Liu</b>.<br> 
                        In <a href="https://cvpr.thecvf.com/Conferences/2024"> CVPR</a>, 2024.
                        </p></li> 

                        <li><p>
                        Enhanced Motion-Text Alignment for Image- to-Video Transfer Learning.  <br>        
                        W. Zhang, C. Wan, <b>T. Liu</b>, X. Tian, X. Shen, and J. Ye.<br> 
                        In <a href="https://cvpr.thecvf.com/Conferences/2024"> CVPR</a>, 2024.
                        </p></li> 

                        <li><p>
                        E2HQV: High-Quality Video Generation from Event Camera via Theory-Inspired Model-Aided Deep Learning.   <br>        
                        Q. Qu, Y. Shen, X. Chen, Y. Chung, and <b>T. Liu</b>.<br> 
                        In <a href="https://aaai.org/aaai-conference/"> AAAI</a>, 2024.
                        </p></li> 

                        <li><p>
                        Exploring Channel-Aware Typical Features for Out-of-Distribution Detection.  <br>        
                        R. He, Y. Yuan, Z. Han, F. Wang, W. Su, Y. Yin, <b>T. Liu</b>, and Y. Gong.<br> 
                        In <a href="https://aaai.org/aaai-conference/"> AAAI</a>, 2024.
                        </p></li> 

                           
                        <li><p>
                        Improving Non-Transferable Representation Learning by Harnessing Content and Style. [<font color="red">Spotlight</font>]   <br>        
                        Z. Hong, Z. Wang, L. Shen, Y. Yao, Z. Huang, S. Chen, C. Yang, M. Gong, and <b>T. Liu</b>.<br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                        
                        <li><p>
                        Beyond Linear Spherical Interpolation: Noise Correction for Image Interpolation with Diffusion Models. [<font color="red">Spotlight</font>]<br>
                        P. Zheng, Y. Zhang, Z. Fang, <b>T. Liu</b>, D. Lian, and B. Han. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
            
                        <li><p>
                        Negative Label Guided OOD Detection with Pretrained Vision-Language Models. [<font color="red">Spotlight</font>]<br>
                        X. Jiang, F. Liu, Z. Fang, H. Chen, <b>T. Liu</b>, F. Zheng, B. Han. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                                                   
                        <li><p>
                        Early Stopping Against Label Noise Without Validation Data.<br>
                        S. Yuan, L. Feng, and <b>T. Liu</b>. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Causal Structure Recovery with Latent Variables under Milder Distributional and Graphical Assumptions.<br>
                        X. Li, K. Zhang, and <b>T. Liu</b>. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Enhancing Contrastive Learning for Ordinal Regression via Ordinal Content Preserved Data Augmentation.<br>
                        J. Zheng, Y. Yao, B. Han, D. Wang, and <b>T. Liu</b>. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models.<br>
                        S. Zhang, X. Xia, Z. Wang, L. Chen, J. Liu, Q. Wu, and <b>T. Liu</b>. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        On the Over-Memorization During Natural, Robust and Catastrophic Overfitting.<br>
                        R. Lin, C. Yu, B. Han, and <b>T. Liu</b>.<br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Neural Auto-designer for Enhanced Quantum Kernels.<br>
                        C. Lei, Y. Du, P. Mi, J. Yu, and <b>T. Liu</b>. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting.<br>
                        R. Dai, Y. Zhang, A. Li, <b>T. Liu</b>, X. Yang, B. Han. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Out-of-Distribution Detection with Negative Prompts.<br>
                        J. Nie, Y. Zhang, Z. Fang, <b>T. Liu</b>, B. Han, X. Tian. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Federated Causal Discovery from Heterogeneous Data.<br>
                        L. Li, I. Ng, G. Luo, B. Huang, G. Chen, <b>T. Liu</b>, B. Gu, and K. Zhang. <br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        FedImpro: Measuring and Improving Client Update in Federated Learning. <br>
                        Z. Tang, Y. Zhang, S. Shi, X. Tian, <b>T. Liu</b>, B. Han, and X. Chu. <br>
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                                    
                        <li><p>
                        Negative Label Guided OOD Detection with Pretrained Vision-Language Models.<br>
                        X. Jiang, F. Liu, Z. Fang, H. Chen, <b>T. Liu</b>, F. Zheng, and B. Han.<br> 
                        In <a href="https://iclr.cc/Conferences/2024"> ICLR</a>, 2024.
                        </p></li> 
                           
                <li><p>
                Eliminating Catastrophic Overfitting Via Abnormal Adversarial Examples Regularization. [<a href="https://openreview.net/pdf?id=Oj7Mrb4009">PDF</a>] [<a href="https://github.com/tmllab/2023_NeurIPS_AAER">CODE</a>]<br>
                R. Lin, C. Yu, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 
                           
                <li><p>
                InstanT: Semi-supervised Learning with Instance-dependent Thresholds. [<a href="https://openreview.net/pdf?id=txv7TnPvOi">PDF</a>] [<a href="https://github.com/tmllab/2023_NeurIPS_InstanT">CODE</a>]<br>
                M. Li, R. Wu, H. Liu, J. Yu, X. Yang, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 

                <li><p>
                CS-Isolate: Extracting Hard Confident Examples by Content and Style Isolation. [<a href="https://openreview.net/pdf?id=Lkc0KjsDFv">PDF</a>] [<a href="https://github.com/tmllab/2023_NeurIPS_CS-isolate">CODE</a>]<br>
                Y. Lin, Y. Yao, X. Shi, M. Gong, X. Shen, D. Xu, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 


                <li><p>
                Subclass-Dominant Label Noise: A Counterexample for the Success of Early Stopping. [<a href="https://openreview.net/pdf?id=kR21XsZeAr">PDF</a>] [<a href="https://github.com/tmllab/2023_NeurIPS_SDN">CODE</a>]<br>
                Y. Bai, Z. Han, E. Yang, J. Yu, B. Han, D. Wang, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 

                           
                <li><p>
                FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness for Semi-Supervised Learning. [<a href="https://openreview.net/pdf?id=pE3yaP0Eqg">PDF</a>] [<a href="https://github.com/tmllab/2023_NeurIPS_FlatMatch">CODE</a>]<br>
                Z. Huang, L. Shen, J. Yu, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 
                           
                <li><p>
                Towards Label-free Scene Understanding by Vision Foundation Models. [<a href="https://openreview.net/pdf?id=C8JdyM7B8I">PDF</a>] [<a href="https://github.com/runnanchen/Label-Free-Scene-Understanding">CODE</a>]<br>
                R. Chen, Y. Liu, L. Kong, N. Chen, X. Zhu, Y. Ma, <b>T. Liu</b>, and W. Wang.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 

                           
                <li><p>
                Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources. [<a href="https://openreview.net/pdf?id=87Qnneer8l">PDF</a>] [<a href="https://github.com/tmlr-group/ATOL">CODE</a>]<br>
                H. Zheng, Q. Wang, Z. Fang, X. Xia, F. Liu, <b>T. Liu</b>, and B. Han.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 

                <li><p>
                Diversified Outlier Exposure for Out-of-Distribution Detection via Informative Extrapolation. [<a href="https://openreview.net/pdf?id=RuxBLfiEqI">PDF</a>] [<a href="https://github.com/tmlr-group/DivOE">CODE</a>]<br>
                J. Zhu, G. Yu, J. Yao, <b>T. Liu</b>, G. Niu, M. Sugiyama, and B. Han.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 


                <li><p>
                FedFed: Feature Distillation against Data Heterogeneity in Federated Learning. [<a href="https://openreview.net/pdf?id=phnGilhPH8">PDF</a>] [<a href="https://github.com/visitworld123/FedFed">CODE</a>]<br>
                Z. Yang, Y. Zhang, Y. Zheng, X. Tian, H. Peng, <b>T. Liu</b>, and B. Han.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 
                           
                <li><p>
                Defending against Data-Free Model Extraction by Distributionally Robust Defensive Training. [<a href="https://openreview.net/pdf?id=7DZAVpOoAK">PDF</a>] <br>
                Z. Wang, L. Shen, <b>T. Liu</b>, T. Duan, Y. Zhu, D. Zhan, D. Doermann, and M. Gao.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 

                           
                <li><p>
                An Efficient Dataset Condensation Plugin and Its Application to Continual Learning. [<a href="https://openreview.net/pdf?id=Murj6wcjRw">PDF</a>]<br>
                E. Yang, L. Shen, Z. Wang, <b>T. Liu</b>, and G. Guo.<br>
                In <a href="https://nips.cc/Conferences/2023"> NeurIPS</a>, 2023.
                </p></li> 


                           
                <li><p>
                Holistic Label Correction for Noisy Multi-Label Classification. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICCV_HLC">CODE</a>]<br>
                X. Xia, J. Deng, W. Bao, Y. Du, B. Han, S. Shan, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li> 
                           
                <li><p>
                Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICCV_CoDis">CODE</a>]<br>
                X. Xia, B. Han, Y, Zhan, J. Yu, M. Gong, C. Gong, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li>  
                           
                           
                <li><p>
                Late Stopping: Avoiding Confidently Learning from Mislabeled Examples. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.pdf">PDF</A>] [CODE]<br>
                S. Yuan, L. Feng, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li>    
                           
                <li><p>
                PADDLES: Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICCV_PADDLES">CODE</a>]<br>
                H. Huang, H. Kang, S. Liu, O. Salvado, T. Rakotoarivelo, D. Wang, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li> 
                           
                <li><p>
                HumanMAC: Masked Motion Completion for Human Motion Prediction. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf">PDF</A>] [<a href="https://github.com/linghaoChan/HumanMAC">CODE</a>] [<a href="https://lhchen.top/Human-MAC/">Webpage</a>]<br>
                L. Chen, J. Zhang, Y. Li, Y. Pang, X. Xia, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li>                        
    
                <li><p>
                Point-Query Quadtree for Crowd Counting, Localization, and More. [<A href="https://arxiv.org/pdf/2308.13814.pdf">PDF</A>] [<a href="https://github.com/cxliu0/PET">CODE</a>]<br>
                C. Liu, H. Lu, Z. Cao, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li> 
                           
                <li><p>
                ALIP: Adaptive Language-Image Pre-training with Synthetic Caption. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf">PDF</A>] [<a href="https://github.com/deepglint/ALIP">CODE</a>]<br>
                K. Yang, J. Deng, X. An, J. Li, Z. Feng, J. Guo, J. Yang, and <b>T. Liu</b>.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li> 
                           
                <li><p>
                Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering. [<A href="https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf">PDF</A>]<br>
                D. Hu, Z. Zhang, T. Hou, <b>T. Liu</b>, H. Fu, and M. Gong.<br>
                In <a href="https://iccv2023.thecvf.com/"> ICCV</a>, 2023.
                </p></li> 
                           
                <li><p>
                Phase-aware Adversarial Defense for Improving Adversarial Robustness. [<A href="https://proceedings.mlr.press/v202/zhou23m/zhou23m.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_PAD">CODE</a>]<br>
                D. Zhou, N. Wang, H. Yang, X. Gao, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>             
                           
                <li><p>
                Eliminating Adversarial Noise via Information Discard and Robust Representation Restoration. [<A href="https://proceedings.mlr.press/v202/zhou23b/zhou23b.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_DIR">CODE</a>]<br>
                D. Zhou, Y. Chen, N. Wang, D. Liu, X. Gao, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>
                           
                <li><p>
                Which is Better for Learning with Noisy Labels: The Semi-supervised Method or Modeling Label Noise? [<A href="https://proceedings.mlr.press/v202/yao23a/yao23a.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_Which-is-Better-for-Learning-with-Noisy-Labels">CODE</a>]<br>
                Y. Yao, M. Gong, Y. Du, J. Yu, B. Han, K. Zhang, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  

                           
                           
                <li><p>
                Exploring Model Dynamics for Accumulative Poisoning Discovery. [<A href="https://proceedings.mlr.press/v202/zhu23d/zhu23d.pdf">PDF</A>] [<a href="https://github.com/tmlr-group/Memorization-Discrepancy">CODE</a>]<br>
                J. Zhu, X. Guo, J. Yao, C. Du, L. He, S. Yuan, <b>T. Liu</b>, L. Wang, B. Han.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  
                           
                <li><p>
                Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability. [<A href="https://arxiv.org/pdf/2306.03715.pdf">PDF</A>] [<a href="https://github.com/tmlr-group/Unleashing-Mask">CODE</a>]<br>
                J. Zhu, H. Li, J. Yao, <b>T. Liu</b>, J. Xu, and B. Han.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li> 

                           
                <li><p>
                Detecting Out-of-distribution Data through In-distribution Class Prior. [<A href="https://proceedings.mlr.press/v202/jiang23e/jiang23e.pdf">PDF</A>] [<a href="https://github.com/tmlr-group/class_prior">CODE</a>]<br>
                X. Jiang, F. Liu, Z. Fang, H. Chen, <b>T. Liu</b>, F. Zheng, and B. Han.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  
                           
                                                      
                <li><p>
                Evolving Semantic Prototype Improves Generative Zero-Shot Learning. [<A href="https://arxiv.org/pdf/2306.06931.pdf">PDF</A>]<br>
                S. Chen, W. Hou, Z. Hong, X. Ding, Y. Song, X. You, <b>T. Liu</b>, and K. Zhang.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  
                            
                <li><p>
                Diversity-enhancing Generative Network for Few-shot Hypothesis Adaptation. [<A href="https://proceedings.mlr.press/v202/dong23d/dong23d.pdf">PDF</A>] [<a href="https://github.com/tmlr-group/DEG-Net">CODE</a>]<br>
                R. Dong, F. Liu, H. Chi, <b>T. Liu</b>, M. Gong, G. Niu, M. Sugiyama, B. Han.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  
                           
                <li><p>
                A Universal Unbiased Method for Classification from Aggregate Observations. [<A href="https://proceedings.mlr.press/v202/wei23a/wei23a.pdf">PDF</A>]<br>
                Z. Wei, L. Feng, B. Han, <b>T. Liu</b>, G. Niu, X. Zhu, and H.T. Shen.<br>
                In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
                </p></li>  

                <li><p>
                Robust Generalization against Corruptions via Worst-Case Sharpness Minimization. [<A href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Robust_Generalization_Against_Photon-Limited_Corruptions_via_Worst-Case_Sharpness_Minimization_CVPR_2023_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_CVPR_SharpDRO"> CODE</a>]<br>
                Z. Huang, M. Zhu, X. Xia, L. Shen, Y. Yu, C. Gong, B. Han, B. Du, and <b>T. Liu</b>.<br>
                In <a href="https://cvpr2023.thecvf.com/"> CVPR</a>, 2023.
                </p></li>  
                           
                <li><p>
                BiCro: Noisy Correspondence Rectification for Multi-modality Data via Bi-directional Cross-modal Similarity Consistency. [<A href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BiCro_Noisy_Correspondence_Rectification_for_Multi-Modality_Data_via_Bi-Directional_Cross-Modal_CVPR_2023_paper.pdf">PDF</A>] [<a href="https://github.com/xu5zhao/BiCro">CODE</a>]<br>
                S. Yang, X. Pan, K. Wang, Y. You, H. Yao, <b>T. Liu</b>, and M. Xu.<br>
                In <a href="https://cvpr2023.thecvf.com/"> CVPR</a>, 2023.
                </p></li>  
                
                <li><p>
                Architecture, Dataset and Model-Scale Agnostic Data-free Meta-Learning. [<A href="https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Architecture_Dataset_and_Model-Scale_Agnostic_Data-Free_Meta-Learning_CVPR_2023_paper.pdf">PDF</A>] [<a href="https://github.com/Egg-Hu/PURER">CODE</a>]<br>
                Z. Hu, L. Shen, Z. Wang, <b>T. Liu</b>, C. Yuan, and D. Tao.<br>
                In <a href="https://cvpr2023.thecvf.com/"> CVPR</a>, 2023.
                </p></li>   
                                                      
                <li><p>
                DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting. [<A href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_DeepSolo_Let_Transformer_Decoder_With_Explicit_Points_Solo_for_Text_CVPR_2023_paper.pdf">PDF</A>] [<a href="https://github.com/ViTAE-Transformer/DeepSolo">CODE</a>]<br>
                M. Ye, J. Zhang, S. Zhao, J. Liu, <b>T. Liu</b>, B. Du, and D. Tao.<br>
                In <a href="https://cvpr2023.thecvf.com/"> CVPR</a>, 2023.
                </p></li>                
                           
                
                <li><p>
                Mosaic Representation Learning for Self-supervised Visual Pre-training. [<A href="https://openreview.net/pdf?id=JAezPMehaUu">PDF</A>] [<a href="https://github.com/tmllab/2023_ICLR_MosRep"> CODE</a>] [<font color="red">Notable-top-25%</font>]<br>
                Z. Wang, Z. Chen, Y. Li, Y. Guo, J. Yu, M. Gong, and <b>T. Liu</b>.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                           
                <li><p>
                Harnessing Out-Of-Distribution Examples via Augmenting Content and Style. [<A href="https://openreview.net/pdf?id=boNyg20-JDm">PDF</A>] [<a href="https://github.com/tmllab/2023_ICLR_HOOD">CODE</a>]<br>
                Z. Huang, X. Xia, L. Shen, B. Han, M. Gong, C. Gong, and <b>T. Liu</b>.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                
                <li><p>
                Unicom: Universal and Compact Representation Learning for Image Retrieval. [<A href="https://arxiv.org/pdf/2304.05884.pdf">PDF</A>] [<a href="https://github.com/deepglint/unicom">CODE</a>]<br>
                X. An, J. Deng, K. Yang, J. Li, Z. Feng, J. Guo, J. Yang, and <b>T. Liu</b>.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>  
                          
                <li><p>
                Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning. [<A href="https://openreview.net/pdf?id=7D5EECbOaf9">PDF</A>] [<a href="https://github.com/tmllab/2023_ICLR_Moderate-DS"> CODE</a>]<br>
                X. Xia, J. Liu, J. Yu, X. Shen, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                           
                <li><p>
                A Holistic View of Noise Transition Matrix in Deep Learning and Beyond. [<A href="https://openreview.net/pdf?id=aFzaXRImWE">PDF</A>] [<a href="https://github.com/pipilurj/ROBOT">CODE</a>] [<font color="red">Spotlight</font>]<br>
                L. Yong, R. Pi, W. Zhang, X. Xia, J. Gao, X. Zhou, <b>T. Liu</b>, and B. Han.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                           
                <li><p>
                Out-of-distribution Detection with Implicit Outlier Transformation. [<A href="https://openreview.net/pdf?id=hdghx6wbGuD">PDF</A>] [<a href="https://github.com/QizhouWang/DOE">CODE</a>]<br>
                Q. Wang, J. Ye, F. Liu, Q. Dai, M. Kalander, <b>T. Liu</b>, J. Hao, and B. Han.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                
                <li><p>
                Contextual Convolutional Networks. [<A href="https://openreview.net/pdf?id=PldynS56bN">PDF</A>] [<a href="https://github.com/liang4sx/contextual_cnn">CODE</a>]<br>
                S. Liang, X. Shen, <b>T. Liu</b>, and X. Hua.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li> 
                           
                <li><p>
                Combating Exacerbated Heterogeneity for Robust Decentralized Models. [<A href="https://openreview.net/pdf?id=eKllxpLOOm">PDF</A>] [<a href="https://github.com/ZFancy/SFAT">CODE</a>]<br>
                J. Zhu, J. Yao, <b>T. Liu</b>, Q. Yao, J. Xu, and B. Han.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li>
                          
                
                <li><p>
                Symmetric Pruning in Quantum Neural Networks. [<A href="https://openreview.net/pdf?id=K96AogLDT2K">PDF</A>] [<font color="red">Notable-top-25%</font>]<br>
                X. Wang, J. Liu, <b>T. Liu</b>, Y. Luo, Y. Du, and D. Tao.<br>
                In <a href="https://iclr.cc/"> ICLR</a>, 2023.
                </p></li> 
                           
                           
                           
                <li><p>
                RSA: Reducing Semantic Shift from Aggressive Augmentations for Self-supervised Learning. [<A href="https://openreview.net/pdf?id=Cgmk9CicWFl">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_RSA">CODE</a>]<br>
                Y. Bai, E. Yang, Z. Wang, Y. Du, B. Han, C. Deng, D. Wang, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning. [<A href="https://openreview.net/pdf?id=GwXrGy_vc8m">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_Multi-Label-T">CODE</a>] [<font color="red">Spotlight</font>]<br>
                S. Li, X. Xia, H. Zhang, Y. Zhan, S. Ge, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization. [<A href="https://openreview.net/pdf?id=IvnoGKQuXi">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_Class-Dependent-Label-Noise-Learning-with-Cycle-Consistency-Regularization">CODE</a>]<br>
                D. Cheng, Y. Ning, N. Wang, X. Gao, H. Yang, Y. Du, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks. [<A href="https://openreview.net/pdf?id=s7SukMH7ie9">PDF</A>] [<a href="https://github.com/RoyalSkye/ATCL">CODE</a>]<br>
                J. Zhou, J. Zhu, J. Zhang, <b>T. Liu</b>, G. Niu, B. Han, and M. Sugiyama.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Towards Lightweight Black-Box Attack Against Deep Neural Networks. [<A href="https://openreview.net/pdf?id=Gpqqm4p91Ez">PDF</A>] [<a href="https://github.com/sunch-ustc/Error_TransFormer/tree/ETF">CODE</a>]<br>
                C. Sun, Y. Zhang, C. Wan, Q. Wang, Y. Li, <b>T. Liu</b>, B. Han, and X. Tian.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Pluralistic Image Completion with Probabilistic Mixture-of-Experts. [<A href="https://openreview.net/pdf?id=wuunqp9KVw">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_PICMM">CODE</a>]<br>
                X. Xia, W. Yang, J. Ren, Y. Li, Y. Zhan, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                         
                           
                <li><p>
                Counterfactual Fairness with Partially Known Causal Graph. [<A href="https://arxiv.org/pdf/2205.13972.pdf">PDF</A>] [<a href="https://github.com/aoqiz/Counterfactual-Fairness-with-Partially-Known-Causal-Graph">CODE</a>]<br>
                A. Zuo, S. Wei, <b>T. Liu</b>, B. Han, K. Zhang, and M. Gong.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Learning Causally Invariant Representations for Out-of-Distribution Generalization on Graphs. [<A href="https://openreview.net/pdf?id=A6AFK_JwrIW">PDF</A>] [<a href="https://github.com/LFhase/CIGA">CODE</a>]<br>
                Y. Chen, Y. Zhang, Y. Bian, H. Yang, K. Ma, B. Xie, <b>T. Liu</b>, B. Han, and J. Cheng.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                           
                <li><p>
                MissDAG: Causal Discovery in the Presence of Missing Data with Continuous Additive Noise Models. [<A href="https://proceedings.neurips.cc/paper_files/paper/2022/file/206361867abf7eb01746c3943078da3c-Paper-Conference.pdf">PDF</A>] [<a href="https://github.com/ErdunGAO/MissDAG">CODE</a>]<br>
                E. Gao, I. Ng, M. Gong, L. Shen, W. Huang, <b>T. Liu</b>, K. Zhang, and H. Bondell.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                           
                <li><p>
                Watermarking for Out-of-distribution Detection. [<A href="https://proceedings.neurips.cc/paper_files/paper/2022/file/63fa7efdd3bcf944a4bd6e0ff6a50041-Paper-Conference.pdf">PDF</A>] [<a href="https://github.com/QizhouWang/watermarking">CODE</a>] [<font color="red">Spotlight</font>]<br>
                Q. Wang, F. Liu, Y. Zhang, J. Zhang, C. Gong, <b>T. Liu</b>, and B. Han.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                           
                <li><p>
                Out-of-Distribution Detection with An Adaptive Likelihood Ratio on Informative Hierarchical VAE. [<A href="https://proceedings.neurips.cc/paper_files/paper/2022/file/3066f60a91d652f4dc690637ac3a2f8c-Paper-Conference.pdf">PDF</A>]<br>
                Y. Li, C. Wang, X. Xia, <b>T. Liu</b>, X. Miao, and B. An.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>

                           
                <li><p>
                Modeling Adversarial Noise for Adversarial Defense. [<A href="https://arxiv.org/abs/2109.09901">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_MAN">CODE</a>]<br>
                D. Zhou, N. Wang, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                           
                <li><p>
                Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network. [<A href="https://proceedings.mlr.press/v162/yang22p/yang22p.pdf">PDF</A>] [<a href="https://github.com/ShuoYang-1998/BLTM">CODE</a>] <br>
                S. Yang, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                           
                <li><p>
                Improving Adversarial Robustness via Mutual Information Estimation. [<A href="https://proceedings.mlr.press/v162/zhou22j/zhou22j.pdf">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_MIAT">CODE</a>]<br>
                D. Zhou, N. Wang, X. Gao, B. Han, X. Wang, Y. Zhan, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
        
                           
                <li><p>
                Understanding Robust Overfitting of Adversarial Training and Beyond. [<A href="https://arxiv.org/pdf/2206.08675.pdf">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_Understanding-Robust-Overfitting">CODE</a>]<br>
                C. Yu, B. Han, L. Shen, J. Yu, C. Gong, M. Gong, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                           
                <li><p>
                To Smooth or Not? When Label Smoothing Meets Noisy Labels. [<A href="https://proceedings.mlr.press/v162/wei22b/wei22b.pdf">PDF</A>] [<a href="https://github.com/UCSC-REAL/negative-label-smoothing">CODE</a>] [<font color="red">Long Talk</font>]<br>
                J. Wei, H. Liu, <b>T. Liu</b>, G. Niu, M. Sugiyama, and Y. Liu.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                           
                <li><p>
                Sample-Efficient Kernel Mean Estimator with Marginalized Corrupted Data. [<A href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539318?casa_token=HcSCI55jxr8AAAAA:2AitzO65vAML4E3f0BzufJPa2kMU8jCDnrol6E2w_XwrYMTSl6HC7qogqY4B3AkAzZk5GIWEVe0">PDF</A>]<br>
                X. Xia, S. Shan, M. Gong, N. Wang, F. Gao, H. Wei, and <b>T. Liu</b>.<br>
                In <a href="https://kdd.org/kdd2022"> KDD</a>, 2022.
                </p></li>
                           
                <li><p>
                Bilateral Dependency Optimization: Defending Against Model-inversion Attacks. [<A href="https://arxiv.org/pdf/2206.05483.pdf">PDF</A>] [<a href="https://github.com/AlanPeng0897/Defend_MI">CODE</a>]<br>
                X. Peng, F. Liu, J. Zhang, L. Lan, J. Ye, <b>T. Liu</b>, and B. Han.<br>
                In <a href="https://kdd.org/kdd2022"> KDD</a>, 2022.
                </p></li>
                           
                <li><p>
                Robust Weight Perturbation for Adversarial Training. [<A >PDF</A>] [<a href="https://github.com/tmllab/2022_IJCAL_Robust-Weight-Perturbation">CODE</a>]<br>
                C. Yu, B. Han, M. Gong, L. Shen, S. Ge, B. Du, and <b>T. Liu</b>.<br>
                In <a href="https://ijcai-22.org/"> IJCAI</a>, 2022.
                </p></li>
                           
               <li><p>
               Fair Classification with Instance-dependent Label Noise. [<A HREF="https://openreview.net/forum?id=s-pcpETLpY">PDF</A>] [<a href="https://github.com/scifancier/Robust-Counterfactually-Fair-Classification">CODE</a>]<br>
               S. Wu, M. Gong, B. Han, Y. Liu, and <b>T. Liu</b><br>
               In <a href="https://www.cclear.cc/"> CLeaR</a>, 2022.
               </p></li>
                           
               <li><p>
               Selective-Supervised Contrastive Learning with Noisy Labels. [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf">PDF</a>] [<A href="https://github.com/tmllab/2022_CVPR_Sel-CL">CODE</A>] <br>
               S. Li, X. Xia, S. Ge, and <b>T. Liu</b>.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
               
            
            
               <li><p>
               CRIS: CLIP-Driven Referring Image Segmentation. [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.pdf">PDF</a>] [<a href="https://github.com/tmllab/2022_CVPR_CRIS.pytorch">CODE</a>] <br>
               Z. Wang, Y. Lu, Q. Li, X. Tao, Y. Guo, M. Gong, and <b>T. Liu</b>.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
               <li><p>
               Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC. [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.pdf">PDF</a>] [<a href="https://github.com/deepinsight/insightface/tree/master/recognition/partial_fc">CODE A</a>] [<a href="https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch">CODE B</a>]<br>
               X. An, J. Deng, J. Guo, Z. Feng, X. Zhu, J. Yang, and <b>T. Liu</b>.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
               <li><p>
               Exploring Set Similarity for Dense Self-supervised Representation Learning. [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf">PDF</a>] [<a href="https://github.com/tmllab/2022_CVPR_SetSim">CODE</a>] <br>
               Z. Wang, Q. Li, G. Zhang, P. Wan, W. Zheng, N. Wang, M. Gong, and <b>T. Liu</b>.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
               <li><p>
               Instance-Dependent Label-Noise Learning With Manifold-Regularized Transition Matrix Estimation. [<a href="https://arxiv.org/pdf/2206.02791.pdf">PDF</a>] [<a href="https://github.com/tmllab/2022_CVPR_MEIDTM">CODE</a>] <br>
               D. Cheng, <b>T. Liu</b>, Y. Ning, N. Wang, B. Han, G. Niu, X. Gao, and M. Sugiyama.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Mutual Quantization for Cross-Modal Search with Noisy Labels.  [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.pdf">PDF</a>] <br>
               E. Yang, D. Yao, <b>T. Liu</b>, and C. Deng.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
               <li><p>
               SimT: Handling Open-set Noise for Domain Adaptive Semantic Segmentation.  [<a href="https://arxiv.org/pdf/2203.15202.pdf">PDF</a>] [<a href="https://github.com/CityU-AIM-Group/SimT">CODE</a>] <br>
               X. Guo, J. Liu, <b>T. Liu</b>, and Y. Yuan.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
            
               <li><p>
               Train Me to Fight: An On-Device Personalized and Machine-Learning-Based Malware Detection. <br>
               A. Pasdar, Y. Lee, <b>T. Liu</b>, and S. Hong<br>
               In <a href="https://fcrlab.unime.it/ccgrid22/"> CCGRID</a>, 2022.
               </p></li>
                           
                           
               <li><p>
               Rethinking Class-Prior Estimation for Positive-Unlabeled Learning. [<A HREF="https://openreview.net/forum?id=aYAA-XHKyk&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/tmllab/2022_ICLR_Rethinking-Class-Prior-Estimation-for-Positive-Unlabeled-Learning">CODE</a>] <br>
               Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, G. Niu, M. Sugiyama, and D. Tao<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Sample Selection with Uncertainty of Losses for Learning with Noisy Labels. [<A HREF="https://openreview.net/forum?id=xENf4QUL4LW&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/tmllab/2022_ICLR_CNLCU">CODE</a>] <br>
               X. Xia, <b>T. Liu</b>, B. Han, M. Gong, J. Yu, G. Niu, and M. Sugiyama<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Adversarial Robustness Through the Lens of Causality. [<A HREF="https://openreview.net/forum?id=cZAi1yWpiXQ&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/YonggangZhangUSTC/CausalAdv">CODE</a>] <br>
               Y. Zhang, M. Gong, <b>T. Liu</b>, G. Niu, X. Tian, B. Han, B. Schlkopf, and K. Zhang<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations. [<A HREF="https://openreview.net/forum?id=TBWA6PLJZQm&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>][<a href="https://github.com/UCSC-REAL/cifar-10-100n">CODE</a>] [<a href="http://noisylabels.com/">DATA</a>] <br>
               J. Wei, Z. Zhu, H. Cheng, <b>T. Liu</b>, G. Niu, and Y. Liu<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
                        
               <li><p>
               Exploiting Class Activation Value for Partial-Label Learning. [<A HREF="https://openreview.net/forum?id=qqdXHUGec9h&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/Ferenas/CAVL">CODE</a>] <br>
               F. Zhang, L. Feng, B. Han, <b>T. Liu</b>, G. Niu, T. Qin, and M. Sugiyama<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Reliable Adversarial Distillation with Unreliable Teachers. [<A HREF="https://openreview.net/forum?id=u6TRGdzhfip&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/ZFancy/IAD">CODE</a>]  <br>
               J. Zhu, J. Yao, B. Han, J. Zhang, <b>T. Liu</b>, G. Niu, J. Zhou, J. Xu, and H. Yang<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
               
               
               <li><p>
               Understanding and Improving Graph Injection Attack by Promoting Unnoticeabilitys. [<A HREF="https://openreview.net/forum?id=wkMG8cdvh7-&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/LFhase/GIA-HAO">CODE</a>]  <br>
               Y. Chen, H. Yang, Y. Zhang, M. Kaili, <b>T. Liu</b>, B. Han, and J. Cheng<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Meta Discovery: Learning to Discover Novel Classes given Very Limited Data. [<A HREF="https://openreview.net/forum?id=MEpKGLsY8f&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/Haoang97/MEDI">CODE</a>] [<font color="
                           red">Spotlight</font>]<br>
               H. Chi, F. Liu, W. Yang, L. Lan, <b>T. Liu</b>, B. Han, G. Niu, M. Zhou, and M. Sugiyama<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            

               <li><p>
               Me-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data. [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Bai_Me-Momentum_Extracting_Hard_Confident_Examples_From_Noisily_Labeled_Data_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/Me-Momentum">CODE</a>][<font color="
                          red ">Oral</font>]<br>
               Y. Bai and <b>T. Liu</b><br>
               In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
               </p></li>           
               
               <li><p>
               Removing Adversarial Noise in Class Activation Feature Space. [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Removing_Adversarial_Noise_in_Class_Activation_Feature_Space_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2021_ICCV_CAFD">CODE</a>] <br>
               D. Zhou, N. Wang, C. Peng, X. Gao, X. Wang, J. Yu, and <b>T. Liu</b><br>
               In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
               </p></li>           
                     
                     
                <li><p>
                Understanding and Improving Early Stopping for Learning with Noisy Labels. [<A HREF="https://arxiv.org/abs/2106.15853">PDF</A>] [<a href="https://github.com/tmllab/PES">CODE</a>]<br>
                Y, Bai, E. Yang, B. Han, Y. Yang, J. Li, Y. Mao, G. Niu, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                     
                     
                <li><p>
                Confident-Anchor-Induced Multi-Source-Free Domain Adaptation. [<A HREF="https://papers.nips.cc/paper/2021/file/168908dd3227b8358eababa07fcaf091-Paper.pdf">PDF</A>] [<a href="https://github.com/Learning-group123/CAiDA">CODE</a>]<br>
                J. Dong, Z. Fang, A. Liu, G. Sun, and <b>T. Liu</b>.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                

                <li><p>
                Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] [<a href="https://github.com/tmllab/2021_NeurIPS_Instance-dependent-Label-noise-Learning-under-a-Structural-Causal-Model">CODE</a>]<br>
                Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                
                <li><p>
                Probabilistic Margins for Instance Reweighting in Adversarial Training. [<A HREF="https://arxiv.org/abs/2106.07904">PDF</A>] [<a href="https://github.com/QizhouWang/MAIL?ref=pythonawesome.com">CODE</a>]<br>
                Q. Wang, F. Liu, B. Han, <b>T. Liu</b>, C. Gong, G. Niu, M. Zhou, and M. Sugiyama.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                         
                <li><p>
                TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation. [<A HREF="https://arxiv.org/abs/2106.06326">PDF</A>] [<a href="https://github.com/Haoang97/TOHAN">CODE</a>] [<font color="red">Spotlight</font>]<br>
                H. Chi, F. Liu, W. Yang, L. Lan, <b>T. Liu</b>, B. Han, W. Cheung, and J. Kwok.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
                </p></li>
                
               <li><p>
               A Second-Order Approach to Learning with Instance-Dependent Label Noise. [<A HREF="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.pdf">PDF</A>] [<A HREF="https://github.com/UCSC-REAL/CAL">CODE</A>] [<font color="red">Oral</font>] <br>
               Z. Zhu, <b>T. Liu</b>, and Y. Liu.<br>
               In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
               </p></li>
                
                
               <li><p>
               Revisiting Knowledge Distillation: An Inheritance and Exploration Framework. [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Revisiting_Knowledge_Distillation_An_Inheritance_and_Exploration_Framework_CVPR_2021_paper.pdf">PDF</a>] [<a href="https://github.com/yellowtownhz/IE-KD">CODE</a>] <br>
               Z. Huang, X. Shen, J. Xing, <b>T. Liu</b>, X. Tian, H. Li, B. Deng, J. Huang, and X. Hua.<br>
               In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
               </p></li>

                
               <li><p>
               Relational Subsets Knowledge Distillation for Long-tailed Retinal Diseases Recognition. [<a href="https://arxiv.org/abs/2104.11057">PDF</a>]<br>
               L. Ju, X. Wang, L. Wang, <b>T. Liu</b>, X. Zhao, T. Drummond, D. Mahapatra, Z. Ge<br>
               In <a href="https://miccai2021.org/en/"> MICCAI</a>, 2021.
               </p></li>  
                
                <li><p>
               Confidence Scores Make Instance-dependent Label-noise Learning Possible. [<a href="http://proceedings.mlr.press/v139/berthon21a/berthon21a.pdf">PDF</a>] [<a href="https://github.com/antoninbrthn/CSIDN">CODE</a>] [<font color="red">Long Talk</font>] <br>
               A. Berthon, B. Han, G. Niu, <b>T. Liu</b>, and M. Sugiyama <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>
               
               <li><p>
               Provably End-to-end Label-noise Learning without Anchor Points. [<A HREF="https://arxiv.org/pdf/2102.02400.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICML_Provably-end-to-end-label-noise-learning-without-anchor-points">CODE</A>]<br>
               X. Li, <b>T. Liu</b>, B. Han, G. Niu, and M. Sugiyama<br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>           
                
               <li><p>
               Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels. [<A HREF="http://proceedings.mlr.press/v139/wu21f/wu21f.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICML_Class2Simi">CODE</A>] <br>
               S. Wu*, X. Xia*, <b>T. Liu</b>, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>
                
               <li><p>
               Towards Defending against Adversarial Examples via Attack-Invariant Features. [<A HREF="https://arxiv.org/pdf/2106.05036.pdf">PDF</A>] [<a href="https://github.com/tmllab/2021_ICML_ARN">CODE</a>]<br>
               D. Zhou, <b>T. Liu</b>, B. Han, N. Wang, C. Peng, and X. Gao <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>            
                
               <li><p>
               Maximum Mean Discrepancy is Aware of Adversarial Attacks. [<A HREF="http://proceedings.mlr.press/v139/gao21b/gao21b.pdf">PDF</A>] [<a href="https://github.com/Sjtubrian/SAMMD">CODE</a>]<br>
               R. Gao, F. Liu, J. Zhang, B. Han, <b>T. Liu</b>, G. Niu, M. Sugiyama <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>
              
                
               <li><p>
               Learning Diverse-Structured Networks for Adversarial Robustness. [<A HREF="https://arxiv.org/pdf/2102.01886.pdf">PDF</A>] [<a href="https://github.com/d12306/dsnet">CODE</a>]<br>
               X. Du, J. Zhang, B. Han, <b>T. Liu</b>, Y. Rong, G. Niu, J. Huang, and M. Sugiyama <br>
               In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
               </p></li>
                
                
               <li><p>
               VecNet: A Spectral and Multi-scale Spatial Fusion Deep Network for Pixel-level Cloud Type Classification in Himawari-8 Imagery. <br>
               Z. Wang, X. Kong, Z. Cui, M. Wu, C. Zhang, M. Gong, and <b>T. Liu</b> <br>
               In <a href="https://igarss2021.com/"> IGARSS</a>, 2021.
               </p></li>
               

                
                
               <li><p>
               Robust early-learning: Hindering the memorization of noisy labels. [<A HREF="https://openreview.net/forum?id=Eql5b1_hTE4">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICLR_CDR">CODE</A>] <br>
               X. Xia, <b>T. Liu</b>, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2021.
               </p></li>

               <li><p>
               A Machine Learning Approach for Predicting Human Preference for Graph Layouts.  [<font color="red">Best VisNotes Paper Award</font>]  <br>
               S. Cai, S. Hong, J. Shen, and <b>T. Liu</b>.<br>
               In <a href="http://vis.tju.edu.cn/pvis2021/"> PacificVis</a>, 2021.
               </p></li>
                
                
               <li><p>
               Robust Dual Recurrent Neural Networks for Financial Time Series Prediction. <br>
               J. He, M. Khushi, N. Tran, and <b>T. Liu</b>.<br>
               In <a href="https://www.siam.org/conferences/cm/conference/sdm21"> SDM</a>, 2021.
               </p></li>

               <li><p>
               Learning with Group Noise. [<A HREF="https://arxiv.org/abs/2103.09468">PDF</A>] [<A HREF="https://github.com/QizhouWang/Max-Matching">CODE</A>] <br>
               Q. Wang, J. Yao, C. Gong, <b>T. Liu</b>, M. Gong, H. Yang, and B. Han.<br>
               In <a href="https://aaai.org/Conferences/AAAI-21/"> AAAI</a>, 2021.
               </p></li>

               <li><p>
               Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. [<A HREF="https://arxiv.org/abs/2101.05467">PDF</A>] [<A HREF="https://github.com/QizhouWang/instance-dependent-label-noise">CODE</A>]<br>
               Q. Wang, B. Han, <b>T. Liu</b>, G. Niu, J. Yang, and C. Gong.<br>
               In <a href="https://aaai.org/Conferences/AAAI-21/"> AAAI</a>, 2021.
               </p></li>
                
                
                <li><p>
                Part-dependent Label Noise: Towards Instance-dependent Label Noise. [<A HREF="https://arxiv.org/abs/2006.07836">PDF</A>] [<a href="https://github.com/tmllab/2020_NeurIPS_PTD">CODE</a>] [<font color="red">Spotlight</font>] <br>
                X. Xia, <b>T. Liu</b>, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                </p></li>
                
                            
                <li><p>
                Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. [<A HREF="https://arxiv.org/abs/2006.07805">PDF</A>] [<a href="https://github.com/tmllab/2020_NeurIPS_dual-t-reducing-estimation-error-for-transition-matrix-in-label-noise-learning">CODE</a>]<br>
                Y. Yao, <b>T. Liu</b>,  B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                </p></li>
                
                <li><p>
                Domain Generalization via Entropy Regularization. [<A HREF="https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf">PDF</A>] [<a href="https://github.com/sshan-zhao/DG_via_ER">CODE</a>]<br>
                S. Zhao, M. Gong, <b>T. Liu</b>,  H. Fu, and D. Tao.<br>
                In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
                </p></li>
                
                
                <li><p>
                Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces. [<A HREF="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560715.pdf">PDF</A>] [<a href="https://github.com/deepinsight/insightface/tree/master/recognition/subcenter_arcface">CODE</a>]<br>
                J. Deng, J. Guo, <b>T. Liu</b>, M. Gong, and S Zafeiriou.<br>
                In <a href="https://eccv2020.eu/"> ECCV</a>, 2020.
                </p></li>
                
                
                <li><p>
                Deep Heterogeneous Multi-Task Metric Learning for Visual Recognition and Retrieval. [<A HREF="https://dl.acm.org/doi/10.1145/3394171.3413574">Paper</A>]<br>
                S. Gan, Y. Luo, Y. Wen, <b>T. Liu</b>, and H. Hu.<br>
                In <a href="https://2020.acmmm.org/"> ACM MM</a>, 2020. <br>
                </p></li>

                
                
                <li><p>
                Learning with Bounded Instance- and Label-dependent Label Noise. [<A HREF="https://arxiv.org/abs/1709.03768">PDF</A>] [<a href="https://github.com/tmllab/2020_ICML_Learning-with-bounded-instance-and-label-dependent-label-noise">CODE</a>]<br>
                J. Cheng, <b>T. Liu</b>, K. Rao, and D. Tao.<br>
                In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>
                


                <li><p>
                Label-Noise Robust Domain Adaptation. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1942-Paper.pdf">PDF</A>]<br>
                X. Yu, <b>T. Liu</b>, M. Gong, K. Zhang, K. Batmanghelich, and D. Tao.<br>
                 In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>


                
                <li><p>
                Dual-Path Distillation: A Unified Framework to Improve Black-Box Attacks. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Paper.pdf">PDF</A>]<br>
                Y. Zhang, Y. Li, <b>T. Liu</b>, and X. Tian.<br>
                 In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>

                
                <li><p>
                LTF: A Label Transformation Framework for Correcting Label Shift. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf">PDF</A>] [<a href="https://github.com/CR-Gjx/LTF-Label-Transformation-Framework">CODE</a>]<br>
                J. Guo, M. Gong, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
                 In <a href="https://icml.cc/"> ICML</a>, 2020.
                </p></li>

               
                <li><p>
                Generative-Discriminative Complementary Learning. [<A HREF="https://kayhan.dbmi.pitt.edu/sites/default/files/AAAI_complementary_learning_v4.pdf">PDF</A>] [<a href="https://github.com/xuyanwu/Complementary-GAN">CODE</a>]<br>
                Y. Xu, M. Gong, J. Chen, <b>T. Liu</b>, K. Zhang, and K. Batmanghelich.<br>
                In <a href="http://www.aaai.org/Conferences/AAAI/aaai20.php"> AAAI</a>, 2020.
                </p></li>

                
                <li><p>
                Diversified Bayesian Nonnegative Matrix Factorization. [<A HREF="https://www.aaai.org/Papers/AAAI/2020GB/AAAI-QiaoM.5577.pdf">PDF</A>]<br>
                M. Qiao, J. Yu, <b>T. Liu</b>, X. Wang, and D. Tao.<br>
                In <a href="http://www.aaai.org/Conferences/AAAI/aaai20.php"> AAAI</a>, 2020.
                </p></li>

                <li><p>
                Are Anchor Points Really Indispensable in Label-Noise Learning? [<A HREF="https://arxiv.org/abs/1906.00189">PDF</A>] [<A HREF="https://github.com/tmllab/2019_NeurIPS_T-Revision">CODE</A>]<br>
                X. Xia, <b>T. Liu</b>, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
                In <a href="https://nips.cc/">NeurIPS</a>, 2019.
                </p></li>
                
                

                <li><p>
                Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence. [<A HREF="https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf">PDF</A>]<br>
                F. He, <b>T. Liu</b>, and D. Tao.<br>
                In <a href="https://nips.cc/">NeurIPS</a></i>, 2019.
                </p></li>

                <li><p>
                DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs. [<A HREF="https://arxiv.org/pdf/1905.03465.pdf">PDF</A>]  [<A HREF="code/DistillHash.tar.gz">CODE</A>]<br>
                E. Yang, <b>T. Liu</b>, C. Deng, W. Liu, and D. Tao.<br>
                In <a href="http://cvpr2019.thecvf.com/">CVPR</a></i>, 2019.
                </p></li>


                <li><p>
                Skipping Two Layers in ResNet Makes the Generalization Gap Smaller than Skipping One or No Layer. [<A HREF="https://link.springer.com/chapter/10.1007/978-3-030-16841-4_36">Paper</A>]<br>
                Y. Furusho, <b>T. Liu</b>, and K. Ikeda.<br>
                In <a href="https://innsbddl2019.org/"> INNSBDDL</a>, 2019. <br>
                </p></li>


                
                <li><p>
                Positive and Unlabeled Learning with Label Disambiguation. [<A HREF="https://www.ijcai.org/Proceedings/2019/0590.pdf">PDF</A>]<br>
                C. Zhang, D. Ren, <b>T. Liu</b>, J. Yang, and C. Gong.<br>
                In <a href="https://ijcai-19.org/"> IJCAI</a>, 2019.
                </p></li>


                <li><p>
                Towards Digital Retina in Smart Cities: A Model Generation, Utilization and Communication Paradigm. [<A HREF="https://arxiv.org/pdf/1907.13368.pdf">PDF</A>] [<font color="red">Best Paper Award</font>]  <br>
                Y. Lou, L. Duan, Y. Luo, Z. Chen, <b>T. Liu</b>, S. Wang, and W. Gao.<br>
                In <a href="http://www.icme2019.org/"> ICME</a>, 2019.
                </p></li>



                <li><p>
                An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption. [<A HREF="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_An_Efficient_and_CVPR_2018_paper.pdf">PDF</A>] [<A HREF="code/cvpr18_backup.zip">CODE</a>]<br>
                X. Yu, <b>T. Liu</b>, M. Gong, K. Batmanghelich, and D. Tao.<br>
                In <a href="http://cvpr2018.thecvf.com/">CVPR</a></i>, 2018.
                </p></li>


                <li><p>
                Learning with Biased Complementary Labels. [<A HREF="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdf">PDF</A>] [<A HREF="code/Xiyu_eccv2018_backup.tar.gz">CODE</a>] [<font color="red">Oral</font>]<br>
                X. Yu, <b>T. Liu</b>, M. Gong, and D. Tao.<br>
                In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                </p></li>
                
                <li><p>
                Correcting the Triplet Selection Bias for Triplet Loss. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Baosheng_Yu_Correcting_the_Triplet_ECCV_2018_paper.pdf">PDF</A>]<br>
                B. Yu, <b>T. Liu</b>, M. Gong, C. Ding, and D. Tao.<br>
                In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                </p></li>
                
                <li><p>
                Deep Domain Generalization via Conditional Invariant Adversarial Networks. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ya_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdf">PDF</A>] [<a href="http://staff.ustc.edu.cn/~xinmei/publications_pdf/2018/code-YaLi.zip">CODE</a>] [<font color="red">Oral</font>]<br>
                Y. Li, X. Tian, M. Gong, Y. Liu, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
                In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
                </p></li>
                

                <li><p>
                Quantum Divide-and-Conquer Anchoring for Separable Non-negative Matrix Factorization. [<A HREF="https://www.ijcai.org/proceedings/2018/0289.pdf">PDF</A>]<br>
                Y. Du, <b>T. Liu</b>, Y. Li, R. Duan, and D. Tao.<br>
                In <a href="https://ijcai-18.org/">IJCAI</a>, 2018.
                </p></li>

                <li><p>
                Online Heterogeneous Transfer Metric Learning. [<A HREF="https://www.ijcai.org/proceedings/2018/0350.pdf">PDF</A>]<br>
                Y. Luo, <b>T. Liu</b>, Y. Wen, and D. Tao.<br>
                In <a href="https://ijcai-18.org/">IJCAI</a>, 2018.
                </p></li>
                


                <li><p>
                Semantic Structure-based Unsupervised Deep Hashing. [<A HREF="https://www.ijcai.org/proceedings/2018/0148.pdf">PDF</A>]<br>
                E. Yang, C. Deng, <b>T. Liu</b>, W. Liu, and D. Tao.<br>
                In <a href="https://ijcai-18.org/"> IJCAI</a>, 2018.
                </p></li>   
                


                <li><p>
                Domain Generalization via Conditional Invariant Representations. [<A HREF="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16595">PDF</A>] [<a href="https://mingming-gong.github.io/papers/CIDG.zip">CODE</a>]<br>
                Y. Li, M. Gong, X. Tian, <b>T. Liu</b>, and D. Tao.<br>
                In <a href="http://www.aaai.org/Conferences/AAAI/aaai18.php"> AAAI</a>, 2018
                </p></li>        



                <li><p>
                Robust Angular Local Descriptor Learning.  [<A HREF="https://arxiv.org/abs/1901.07076">PDF</A>]<br>
                Y. Xu, M. Gong, <b>T. Liu</b>, K. Batmanghelich, C. Wang.<br>
                In <a href="http://accv2018.net/"> ACCV</a>, 2018.
                </p></li>



                <li><p>
                Algorithmic Stability and Hypothesis Complexity. [<A HREF="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">PDF</A>]<br>
                <b>T. Liu</b>, G. Lugosi, G. Neu and D. Tao.<br>
                In <a href="https://2017.icml.cc/"> ICML </a>, 2017.
                </p></li>


                <li><p>
                On Compressing Deep Models by Low Rank and Sparse Decomposition. [<A HREF="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_On_Compressing_Deep_CVPR_2017_paper.pdf">PDF</A>]  [<font color="red">Spotlight</font>]<br>
                X. Yu, <b>T. Liu</b>, X. Wang, and D. Tao.<br>
                In <a href="http://cvpr2017.thecvf.com/"> CVPR</a>, 2017.
                </p></li>

                <li><p>
                Understanding How Feature Structure Transfers in Transfer Learning. [<A HREF="https://www.ijcai.org/Proceedings/2017/0329.pdf">PDF</A>]<br>
                <b>T. Liu</b>, Q. Yang, and D. Tao.<br>
                In <a href="https://ijcai-17.org/"> IJCAI</a>, 2017.
                </p></li>

                 <li><p>
                General Heterogeneous Transfer Distance Metric Learning via Knowledge Fragments Transfer.  [<font color="red">Best Paper Award candidate</font>] [<A HREF="https://www.ijcai.org/Proceedings/2017/0341.pdf">PDF</A>]<br>
                Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
                In <a href="https://ijcai-17.org/"> IJCAI</a></i>, 2017.
                </p></li>

                <li><p>
                Domain Adaptation with Conditional Transferable Components. [<A HREF="http://proceedings.mlr.press/v48/gong16.pdf">PDF</A>] [<A HREF="code/CTC.zip">CODE</A>]<br>
                M. Gong, K. Zhang, <b>T. Liu</b>, D. Tao, C. Glymour, and B. Schlkopf.<br>
                In <a href="http://icml.cc/2016/"> ICML</a></i>, 2016.
                </p></li>


                <li><p>
                Diversified Dynamical Gaussian Process Latent Variable Model for Video Repair. [<A HREF="https://dl.acm.org/doi/10.5555/3016387.3016415">Paper</A>]<br>
                H. Xiong, <b>T. Liu</b>, and D. Tao.<br>
                In <a href="http://www.aaai.org/Conferences/AAAI/aaai16.php"> AAAI</a>, 2016. <br>
                </p></li>

                <li><p>
                Spectral Ensemble Clustering.  <br>
                H. Liu*, <b>T. Liu</b>*, J. Wu, D. Tao, and Y. Fu. [<A HREF="https://dl.acm.org/doi/10.1145/2783258.2783287">Paper</A>]<br>
                In <a href="http://www.kdd.org/kdd2015/">KDD</a>, 2015.<br>
                </p></li>

                <li><p>
                Multi-Task Model and Feature Joint Learning. [<A HREF="https://www.ijcai.org/Proceedings/15/Papers/512.pdf">PDF</A>] <br>
                Y. Li, X. Tian, <b>T. Liu</b>, and D. Tao.<br>
                In <a href="http://ijcai-15.org/"> IJCAI</a>, 2015.
                </p></li>

                <li><p>
                Learning Relative Features through Adaptive Pooling for Image Classification.  [<font color="red">Best Paper Award candidate</font>] [<A HREF="https://ieeexplore.ieee.org/document/6890269">Paper</A>]<br>
                M. Shao, S. Li, <b>T. Liu</b>, D. Tao, T. S. Huang, and Y. Fu.<br>
                In <a href="http://www.ieee-icme.org/icme2014/www.icme2014.org/home.html"> ICME</a>, 2014.<br>
                </p></li>

                <li><p>
                On the Robustness and Generalization of Cauchy Regression. [<font color="red">Best Paper Award</font>] [<A HREF="https://ieeexplore.ieee.org/document/6920341">Paper</A>] <br>
                <b>T. Liu</b> and D. Tao.<br>
                In <a href="http://web.siat.ac.cn/icist2014/"> ICIST</a>, 2014.<br>
                </p></li>


                </p></li>
<!--              </ol>
</ul> -->
<h2><a name="cd"></a>Major journal articles</h2>

<!-- <ul >
           <ol reversed>   -->
            <li><p>
            Continual Learning From a Stream of APIs. <br>
            E. Yang, Z. Wang, L. Shen, N. Yin, <b>T. Liu</b>, G. Guo, X. Wang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
            </p></li> 

                           
            <li><p>
            Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. <br>
            S. Li, X. Xia, J. Deng, S. Ge, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
            </p></li> 
                           
            <li><p>
            Learning General and Specific Embedding with Transformer for Few-Shot Object Detection. <br>
            X. Zhang, Z. Chen, J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="https://link.springer.com/journal/11263">IJCV</a></i>, accepted.<br/>
            </p></li> 
                           
            <li><p>
            Winning Prize Comes from Losing Tickets: Improve Invariant Learning by Exploring Variant Parameters for Out-of-Distribution Generalization. <br>
            Z. Huang, M. Li, L. Shen, J. Yu, C. Gong, B. Han, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://link.springer.com/journal/11263">IJCV</a></i>, accepted.<br/>
            </p></li> 

            <li><p>
            Regularly Truncated M-estimators for Learning with Noisy Labels. <br>
            X. Xia, P. Lu, C. Gong, B. Han, J. Yu, J. Yu, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 46(5): 3522-3536, 2024.<br/>
            </p></li> 

            <li><p>
            BadLabel: A Robust Perspective on Evaluating and Enhancing Label-Noise Learning. <br>
            J. Zhang, B. Song, H. Wang, B. Han, <b>T. Liu</b>, L. Liu, and M. Sugiyama.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 46(6): 4398-4409, 2024.<br/>
            </p></li> 

            <li><p>
            A Time-Consistency Curriculum for Learning from Instance-Dependent Noisy Labels. <br>
            S. Wu, T. Zhou, Y. Du, J. Yu, B. Han, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 46(7): 4830-4842, 2024.<br/>
            </p></li> 

            <li><p>
            Tackling Noisy Labels With Network Parameter Additive Decomposition. <br>
            J. Wang, X. Xia, L. Lan, X. Wu, J. Yu, W. Yang, B. Han, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 46(9): 6341-6354, 2024.<br/>
            </p></li> 

            <li><p>
            Exploit CAM by itself: Complementary Learning System for Weakly Supervised Semantic Segmentation. <br>
            W. Yang, J. Mai, F. Zhang, <b>T. Liu</b>, and B. Han.<br>
            <i><a target="_blank" href="https://jmlr.org/tmlr/">TMLR</a></i>, 2024.<br/>
            </p></li>             
                           
            <li><p>
            Conditional Consistency Regularization for Semi-Supervised Multi-Label Image Classification. [<A HREF="https://ieeexplore.ieee.org/document/10283961">Paper</A>]<br>
            Z. Wu, T. He, X. Xia, J. Yu, X. Shen, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, 26: 4206-4216, 2024.<br/>
            </p></li>
               

            <li><p>
            On exploring node-feature and graph-structure diversities for node drop graph pooling. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608023004665">paper</a>] <br>
            C. Liu, Y. Zhan, B. Yu, L. Liu. B. Du, W. Hu, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://www.sciencedirect.com/journal/neural-networks">Neral Networks</a></i>, 167: 559-571, 2023.<br/>
            </p></li> 

            <li><p>
            Extended T: Learning with Mixed Closed-set and Open-set Noisy Labels. [<a href="https://ieeexplore.ieee.org/document/9790332">paper</a>] <br>
            X. Xia, B. Han, N. Wang, J. Deng, J. Li, Y. Miao, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 45(3): 3047-3058, 2023.<br/>
            </p></li> 
                                   
            <li><p>
            Handling Open-Set Noise and Novel Target Recognition in Domain Adaptive Semantic Segmentation. [<a href="https://ieeexplore.ieee.org/document/10048580">paper</a>] <br>
            X. Guo, J. Liu, <b>T. Liu</b>, and Y. Yuan.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 45(8): 9846-9861, 2023.<br/>
            </p></li> 
                           
            <li><p>
            Recent Advances for Quantum Neural Networks in Generative Learning. [<a href="https://ieeexplore.ieee.org/document/10113742">paper</a>] <br>
            J. Tian, X. Sun, Y. Du, S. Zhao, Q. Liu, K. Zhang, W. Yi, W. Huang, C. Wang, X. Wu, M. Hsieh, <b>T. Liu</b>, W. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 45(10): 12321-12340, 2023.<br/>
            </p></li> 

            <li><p>
            A Parametrical Model for Instance-Dependent Label Noise. [<a href="https://ieeexplore.ieee.org/document/10209198">paper</a>] <br>
            S. Yang, S. Wu, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 45(12): 14055-14068, 2023.<br/>
            </p></li> 

            <li><p>
            FedDAG: Federated DAG Structure Learning. <br>
            E. Gao, J. Chen, L. Shen, <b>T. Liu</b>, M. Gong and H. Bondell.<br>
            <i><a target="_blank" href="https://jmlr.org/tmlr/">TMLR</a></i>, 2023.<br/>
            </p></li>
                       
            <li><p>
            KRADA: Known-region-aware Domain Alignment for Open-set Domain Adaptation in Semantic Segmentation. <br>
            C. Zhou, F. Liu, C. Gong, R. Zeng, <b>T. Liu</b>, W. Cheung, and B. Han.<br>
            <i><a target="_blank" href="https://jmlr.org/tmlr/">TMLR</a></i>, 2023.<br/>
            </p></li>     
             

            <li><p>
            Trustable Co-label Learning from Multiple Noisy Annotators. <br>
            S. Li, <b>T. Liu</b>, J. Tan, D. Zeng, and S. Ge.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, 25: 1045-1057, 2023.<br/>
            </p></li>  

            <li><p>
            Relation-Aware Fine-Grained Reasoning Network for Textbook Question Answering. [<A HREF="https://ieeexplore.ieee.org/document/9466370">Paper</A>]<br>
            J. Ma, J. Liu, Y. Wang, J. Li, <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 34(1): 15-27, 2023.<br/>
            </p></li>   

            <li><p>
            Understanding How Pre-Training Regularizes Deep Learning Algorithms. [<A HREF="https://ieeexplore.ieee.org/document/9646441">Paper</A>]<br>
            Y. Yao, B. Yu, C. Gong, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 34(9): 5828-5840, 2023.<br/>
            </p></li>      
                       
                       
            <li><p>
            An Optimal Transport Analysis on Generalization in Deep Learning. [<A HREF="https://ieeexplore.ieee.org/document/9546990">Paper</A>]<br>
            J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 34(6): 2842-2853, 2023.<br/>
            </p></li>
                       
                                   
            <li><p>
            Transferable Coupled Network for Zero-Shot Sketch-Based Image Retrieval. [<A HREF="https://ieeexplore.ieee.org/document/9591307">Paper</A>]<br>
            H. Wang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 44(12): 9181-9194, 2022.<br/>
            </p></li>  
                       
            <li><p>
            Instance-Dependent Positive and Unlabeled Learning with Labeling Bias Estimation. [<A HREF="https://ieeexplore.ieee.org/document/9361303">Paper</A>]<br>
            C. Gong, Q. Wang, <b>T. Liu</b>, B. Han, J. You, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 44(8): 4163-4177, 2022.<br/>
            </p></li>      
                       
                       
            <li><p>
            Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation.[<A HREF="https://ieeexplore.ieee.org/document/9204804">Paper</A>]<br>
            X. Yang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 44(4): 1992-2003, 2022.<br/>
            </p></li> 
                       
                                                                     
            <li><p>
            Bridging the Gap between Few-Shot and Many-Shot Learning via Distribution Calibration. [<A HREF="https://ieeexplore.ieee.org/document/9634045">Paper</A>]<br>
            S. Yang, S. Wu, <b>T. Liu</b>, and M. Xu.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 44(2): 9830-9843, 2022.<br/>
            </p></li>  
                       
                       
   
            <li><p>
            Learning from Noisy Pairwise Similarity and Unlabeled Data. <br>
            S. Wu, <b>T. Liu</b>, B. Han, J. Yu, G. Niu, and M. Sugiyama.<br>
            <i><a target="_blank" href="https://www.jmlr.org/">JMLR</a></i>, 23(307): 1-32, 2022.<br/>
            </p></li>   

            <li><p>
            NoiLIn: Do Noisy Labels Always Hurt Adversarial Training? <br>
            J. Zhang, X. Xu, B. Han, <b>T. Liu</b>, G. Niu, L.Cui, and M. Sugiyama.<br>
            <i><a target="_blank" href="https://jmlr.org/tmlr/">TMLR</a></i>, 2022.<br/>
            </p></li> 

            <li><p>
            Quantum differentially private sparse regression learning. [<A HREF="">Paper</A>]<br>
            Y. Du, M. Hsieh, <b>T. Liu</b>, S. You, and D. Tao.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/document/9749100/">IEEE T-IT</a></i>, 68(8): 5217-5233, 2022.<br/>
            </p></li>  
                       
            <li><p>
            Exploring language hierarchy for video grounding. [<A HREF="">Paper</A>]<br>
            X. Ding, N. Wang, S. Zhang, Z. Huang, X. Li, M. Tang, <b>T. Liu</b>, and X. Gao.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/document/9817030">IEEE T-IP</a></i>, 31(8): 4693-4706, 2022.<br/>
            </p></li>
                       
                       
            <li><p>
            On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes Optimal Classifier. [<A HREF="https://arxiv.org/pdf/1802.03688.pdf">Paper</A>]<br>
            J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 33(10): 5766-5774, 2022.<br/>
            </p></li>
                         
            <li><p>
            Improving medical image classification with label noise using dual-uncertainty estimation. [<A HREF="">Paper</A>]<br>
            L. Ju, X. Wang, L. Wang, D. Mahapatra, X. Zhao, M. Harandi, T. Drummond, <b>T. Liu</b>, and Z. Ge.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/document/9674886/">IEEE T-MI</a></i>, 41(6): 1533-1546, 2022.<br/>
            </p></li>            
                       
                       
            <li><p>
            LR-SVM+: Learning Using Privileged Information with Noisy Labels. [<A HREF="https://ieeexplore.ieee.org/document/9556575">Paper</A>]<br>
            Z. Wu, X. Xia, R. Wang, J. Li, J. Yu, Y. Mao, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, 24: 1080-1092, 2022.<br/>
            </p></li>
               
                      <li><p>
            TWGAN: Twin Discriminator Generative Adversarial Networks. [<A HREF="https://ieeexplore.ieee.org/document/9352520">Paper</A>]<br>
            Z. Zhang, M. Li, H. Xie, J. Yu, <b>T. Liu</b>, and C. W. Chen.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, 24: 677-688, 2022.<br/>
            </p></li>
            
                       
            <li><p>
            Laplacian Welsch Regularization for Robust Semi-Supervised Learning. [<A HREF="https://ieeexplore.ieee.org/document/9020208">Paper</A>]<br>
            J. Ke, C. Gong, <b>T. Liu</b>, L. Zhao, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IEEE T-CYB</a></i>, 51(1): 164-177, 2022.<br/>
            </p></li>

            <li><p>
            Label Propagated Nonnegative Matrix Factorization for Clustering. [<A HREF="https://ieeexplore.ieee.org/document/9044402">Paper</A>]<br>
            L. Lan, <b>T. Liu</b>, X. Zhang, C. Xu, and Z. Luo.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a></i>, 34(1), 340-351, 2022.<br/>
            </p></li>
            
            <li><p>
            Orthogonal Deep Neural Networks.<br>
            K. Jia, S. Li, Y. Wen, <b>T. Liu</b>, and D. Tao. [<A HREF="https://arxiv.org/abs/1905.0592">PDF</A>] <br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 43(4): 1352-1368, 2021.<br/>
            </p></li>
            
            
            <li><p>
            Loss Decomposition and Centroid Estimation for Positive and Unlabeled Learning. [<A HREF="https://ieeexplore.ieee.org/document/8839365">Paper</A>]<br>
            C. Gong, H. Shi, <b>T. Liu</b>, C. Zhang, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 43(3): 918-932, 2021.<br/>
            </p></li>
            
            <li><p>
            A Shape Transformation-based Dataset Augmentation Framework for Pedestrian Detection.<br>
            Z. Chen, W. Ouyang, <b>T. Liu</b>, and D. Tao. [<A HREF="https://arxiv.org/abs/1912.07010">PDF</A>] <br>
            <i><a target="_blank" href="https://www.springer.com/journal/11263">IJCV</a></i>, 129(4): 1121-1138, 2021.<br/>
            </p></li>     
                        
            <li><p>
            HRSiam: High-Resolution Siamese Network, Towards Space-Borne Satellite Video Tracking. [<A HREF="https://ieeexplore.ieee.org/document/9350236">Paper</A>]<br>
            J. Shao, B. Du, C. Wu, M. Gong, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 30(2): 3056-3068, 2021.<br/>

             <li><p>
            KFC: An Efficient Framework for Semi-supervised Temporal Action Localization. <br>
            X. Ding, N Wang, X. Gao, J. Li, X. Wang, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 30(7): 6869-6878, 2021.<br/>

      
            
            <li><p>
            Absent Multiple Kernel Learning Algorithms. [<A HREF="https://ieeexplore.ieee.org/document/8627941">Paper</A>]<br>
            X. Liu, L. Wang, X. Zhu, M. Li, E. Zhu, <b>T. Liu</b>, L. Liu, Y. Dou, and J. Yin.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 42(6): 1303-1316, 2020.<br/>
            </p></li>


            
            <li><p>
            Multiple Kernel k-means with Incomplete Kernels. [<A HREF="https://ieeexplore.ieee.org/document/8611131">Paper</A>]<br>
            X. Liu, X. Zhu, M. Li, L. Wang, E. Zhu, <b>T. Liu</b>, M. Kloft, D. Shen, J. Yin, and W. Gao. <br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 42(5): 1191-1204, 2020.<br/>
            </p></li>
            
            <li><p>
            Two-Stream Deep Hashing with Class-Specific Centers for Image Search. [<A HREF="https://ieeexplore.ieee.org/document/8833511">Paper</A>]<br>
            C. Deng, E. Yang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(6): 2189-2201, 2020<br/>
            </p></li>
            
            
            <li><p>
            Why ResNet Works? Residuals Generalize. [<A HREF="https://arxiv.org/abs/1904.01367">PDF</A>]<br>
            F. He, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(12): 5349-5362, 2020.<br/>
            </p></li>


            <li><p>
            Harnessing Side Information for Classification under Label Noise. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8848850">Paper</A>]<br>
            Y. Wei, C. Gong, S. Chen, <b>T. Liu</b>, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(9): 3178-3192, 2020.<br/>
            </p></li>

            
            <li><p>
            Group Feedback Capsule Network. [<A HREF="https://ieeexplore.ieee.org/document/9099041">Paper</A>]<br>
            X. Ding, N Wang, X. Gao, J. Li, X. Wang, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 29: 6789-6799, 2020.<br/>



            <li><p>
            Towards Efficient Front-end Visual Sensing for Digital Retina: A Model-Centric Paradigm. [<A HREF="https://ieeexplore.ieee.org/document/8960464">Paper</A>]<br>
            Y. Lou, L. Duan, Y. Luo, Z. Chen, <b>T. Liu</b>, S. Wang, and W. Gao.<br>
            <i><a target="_blank" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a></i>, 22(11): 3002-3013, 2020.<br/>
            </p></li>


        	<li><p>
            Adversarial Examples for Hamming Space Search. [<A HREF="https://ieeexplore.ieee.org/document/8573146">Paper</A>]<br>
            E. Yang, <b>T. Liu</b>, C. Deng, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IEEE T-CYB</a></i>, 50(4): 1473-1484, 2020.<br/>
            </p></li>


            <li><p>
            Transferring Knowledge Fragments for Learning Distance Metric from A Heterogeneous Domain. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8333749">Paper</A>] [<a href="https://github.com/yluopku/GB-HTDML">CODE</a>]<br>
            Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(4): 1013-1026, 2019.<br/>
            </p></li>
            

            <li><p>
            Truncated Cauchy Non-negative Matrix Factorization. [<A HREF="https://arxiv.org/abs/1906.00495">PDF</A>] <br>
            N. Guan*, <b>T. Liu</b>*, Y. Zhang, D. Tao, and L. S. Davis.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(1): 246-259, 2019.<br/>
            </p></li>            
            
            <li><p>
            Large-Margin Label-Calibrated Support Vector Machines for Positive and Unlabeled Learning. [<A HREF="https://ieeexplore.ieee.org/document/8636540">Paper</A>]<br>
            C. Gong, <b>T. Liu</b>, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 30(11): 3471-3483, 2019.<br/>
            </p></li>
            

            <li><p>
            Eigenfunction-Based Multitask Learning in a Reproducing Kernel Hilbert Space. [<A HREF="https://ieeexplore.ieee.org/document/8513983">Paper</A>]<br>
            X. Tian, Y. Li, <b>T. Liu</b>, X. Wang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 30(6): 1818-1830, 2019.<br/>
            </p></li>


            <li><p>
            Adaptive Morphological Reconstruction for Seeded Image Segmentation. [<A HREF="https://arxiv.org/abs/1904.03973">PDF</A>] [<A HREF="https://github.com/SUST-reynole/AMR">CODE</A>]<br>
            T. Lei, X. Jia, <b>T. Liu</b>, S. Liu, H. Meng, and A. K. Nandi.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 28(11): 5510-5523, 2019.<br/>
            </p></li>


            <li><p>
            Unsupervised Semantic-Preserving Adversarial Hashing for Image Search. [<A HREF="https://ieeexplore.ieee.org/document/8666767">Paper</A>]<br>
            C. Deng, E. Yang, <b>T. Liu</b>, J. Li, W. Liu, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 28(8): 4032-4044, 2019.<br/>
            </p></li>


            <li><p>
            Fast Supervised Discrete Hashing. [<A HREF="https://ieeexplore.ieee.org/document/7873258">Paper</A>]<br>
            J. Gui*, <b>T. Liu</b>*, Z. Sun, D. Tao, and T. Tan.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 40(2): 490-496, 2018.<br/>
            </p></li>

            <li><p>
            Continuous Dropout. [<A HREF="https://arxiv.org/abs/1911.12675">PDF</A>]<br>
            X. Shen, X. Tian, F. Xu, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 29(9): 3926-3937, 2018.<br/>
            </p></li>


            <li><p>
            Multi-class Learning with Partially Corrupted Labels. [<A HREF="https://ieeexplore.ieee.org/document/7929355">Paper</A>]<br>
            R. Wang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 29(6): 2568-2580, 2018.<br/>
            </p></li>

            <li><p>
            On Better Exploring and Exploiting Task Relationship in Multi-Task Learning: Joint Model and Feature Learning. [<A HREF="https://arxiv.org/abs/1904.01747">PDF</A>]<br>
            Y. Li, X. Tian, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 29(5): 1975-1985, 2018.<br/>
            </p></li>


            <li><p>
            Supervised Discrete Hashing with Relaxation. [<A HREF="https://arxiv.org/abs/1904.03549">PDF</A>]  <br>
            J. Gui*, <b>T. Liu</b>*, Z. Sun, D. Tao, and T. Tan.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 29(3): 608-617, 2018.<br/>
            </p></li>



            <li><p>
            Deep Blur Mapping: Exploiting High-Level Semantics by Deep Neural Networks. [<A HREF="https://arxiv.org/abs/1612.01227">PDF</A>]<br>
            K. Ma, H. Fu, <b>T. Liu</b>, Z. Wang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 27(10): 5155-5166, 2018.<br/>
            </p></li>
            
            <li><p>
            A Regularization Approach for Instance-Based Superset Label Learning. [<A HREF="https://arxiv.org/pdf/1904.02832.pdf">PDF</A>]  <br>
            C. Gong, <b>T. Liu</b>, Y. Tang, J. Yang, J. Yang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IEEE T-CYB</a></i>, 48(3): 967-978, 2018.<br/>
            </p></li>

            <li><p>
            Algorithm-Dependent Generalization Bounds for Multi-Task Learning. [<A HREF="https://ieeexplore.ieee.org/document/7437460">Paper</A>]<br>
            <b>T. Liu</b>, D. Tao, M. Song, and S. J. Maybank.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 39(2): 227-241, 2017.<br/>
            </p></li>


            <li><p>
            Large Cone Non-negative Matrix Factorization. [<A HREF="https://ieeexplore.ieee.org/document/7492255">Paper</A>]<br>
            <b>T. Liu</b>, M. Gong, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 28(9): 2129-2141, 2017.<br/>
            </p></li>



            <li><p>
            dipIQ: Blind Image Quality Assessment by Learning-to-Rank Discriminable Image Pairs. [<A HREF="https://arxiv.org/pdf/1904.06505.pdf">PDF</A>] <br>
            K. Ma, W. Liu, <b>T. Liu</b>, Z. Wang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 26(8): 3951-3964, 2017.<br/>
            </p></li>

            <li><p>
            Elastic Net Hypergraph Learning for Image Clustering and Semi-supervised Classification. [<A HREF="https://ieeexplore.ieee.org/document/7707352">Paper</A>]<br>
            Q. Liu, Y. Sun, C. Wang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 26(1): 452-463, 2017.<br/>
            </p></li>

            <li><p>
            Spectral Ensemble Clustering via Weighted K-means: Theoretical and Practical Evidence. [<A HREF="https://ieeexplore.ieee.org/document/7811216">Paper</A>]<br>
            H. Liu, J. Wu, <b>T. Liu</b>, D. Tao, and Y. Fu.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=4358933">IEEE T-KDE</a></i>, vol. 29, no. 5, pp. 1129-1143, 2017.<br/>
            </p></li>

            <li><p>
            Joint Sparse Representation and Multitask Learning for Hyperspectral Target Detection. [<A HREF="https://ieeexplore.ieee.org/document/7769257">Paper</A>]<br>
            Y. Zhang, B. Du, L. Zhang, and <b>T. Liu</b>.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE T-GRS</a></i>, 55(2): 894-906, 2017.<br/>
            </p></li>


           <li><p>
            Classification with Noisy Labels by Importance Reweighting. [<A HREF="https://arxiv.org/pdf/1411.7718.pdf">PDF</A>]  [<A HREF="https://github.com/tmllab/2015_PAMI_Classification-with-noisy-labels-by-importance-reweighting">CODE</A>]<br>
            <b>T. Liu</b> and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 38(3): 447-461, 2016.<br/>
            </p></li>

            <li><p>
            Dimensionality-Dependent Generalization Bounds for k-Dimensional Coding Schemes.</font> [<A HREF="https://arxiv.org/pdf/1601.00238.pdf">PDF</A>] <br>
            <b>T. Liu</b>, D. Tao, and D. Xu.<br>
            <i><a target="_blank" href="http://www.mitpressjournals.org/loi/neco">NECO</a></i>, 28(10): 2213-2249, 2016.<br/>
            </p></li>


            <li><p>
            On the Performance of MahNMF Manhattan Non-negative Matrix Factorization. [<A HREF="https://ieeexplore.ieee.org/document/7192641">Paper</A>]<br>
            <b>T. Liu</b> and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 27(9): 1851-1863, 2016.<br/>
            </p></li>


            <li><p>
            Dual Diversified Dynamical Gaussian Process Latent Variable Model for Video Repair. [<A HREF="https://ieeexplore.ieee.org/document/7479456">Paper</A>]<br>
            H. Xiong, <b>T. Liu</b>, D. Tao, and H. T. Shen.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 25(8): 3626-3637, 2016.<br/>
            </p></li>

            <li><p>
            Local Rademacher Complexity for Multi-Label Learning. [<A HREF="https://arxiv.org/pdf/1410.6990.pdf">PDF</A>] <br>
            C. Xu, <b>T. Liu</b>, D. Tao, and C. Xu.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 25(3): 1495-1507, 2016.<br/>
            </p></li>


            <li><p>
            Representative Vector Machines: A Unified Framework for Classical Classifiers. [<A HREF="https://ieeexplore.ieee.org/document/7194763">Paper</A>]<br>
            J. Gui*, <b>T. Liu</b>*, D. Tao, Z. Sun, and T. Tan.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">IEEE T-CYB</a></i>, 46(8): 1877-1888, 2016.<br/>
            </p></li>

            <li><p>
            Video Face Editing Using Temporal-Spatial-Smooth Warping. [<A HREF="https://dl.acm.org/doi/10.1145/2819000">Paper</A>]<br>
            X. Li, <b>T. Liu</b>*, J. Deng, and D. Tao.<br>
            <i><a target="_blank" href="http://tist.acm.org/">ACM T-IST</a></i>, 7(3): 32, 2016.<br/>
            </p></li>


            <li><p>
            Deformed Graph Laplacian for Semisupervised Learning. [<A HREF="https://ieeexplore.ieee.org/document/7010929">Paper</A>]<br>
            C. Gong, <b>T. Liu</b>, D. Tao, K. Fu, E. Tu, and J. Yang.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 26(10): 2261-2274, 2015.<br/>
            </p></li>

            <li><p>
            Multiview Matrix Completion for Multilabel Image Classification. [<A HREF="https://arxiv.org/abs/1904.03901">PDF</A>] <br>
            Y. Luo, <b>T. Liu</b>, D. Tao, and C. Xu.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 24(8): 2261-2274, 2015.<br/>
            </p></li>


            <li><p>
            No Reference Quality Assessment for Multiply-Distorted Images Based on an Improved Bag-of-Words Model. [<A HREF="https://ieeexplore.ieee.org/document/7112105">Paper</A>]<br>
            Y. Lu, F. Xie, <b>T. Liu</b>, Z. Jiang, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=97">IEEE SPL</a></i>, 22(10): 1811-1815, 2015.<br/>
            </p></li>

            <li><p>
            Decomposition-Based Transfer Distance Metric Learning for Image Classification. [<A HREF="https://arxiv.org/abs/1904.03846">PDF</A>] <br>
            Y. Luo, <b>T. Liu</b>, D. Tao, and C. Xu.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=83">IEEE T-IP</a></i>, 23(9): 3789-3801, 2014.<br/>
            </p></li>

              </ol>
        </ul>
