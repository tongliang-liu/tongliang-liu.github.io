
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="shortcut icon" href="paper_dragon.ico">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- <link rel="shortcut icon" href="paper_dragon.ico"> -->
    <title>Tongliang Liu's Homepage </title>
    <!-- <base href="https://tongliang-liu.github.io/index.html"> -->
    <!-- <base href="./index.html"> -->
    
    <script type="text/javascript" src="//ra.revolvermaps.com/0/0/8.js?i=0gh03rwju0o&amp;m=0&amp;s=170&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;v0=80" async="async"></script>
    </head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Tongliang Liu</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="groups.html">Group</a></div>
    <div class="menu-item"><a href="talks.html">Talks</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="service.html">Service</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
    <div class="menu-item"><a href="grants.html">Grants</a></div>
    <div class="menu-item"><a href="publications.html">Publications</a></div>
    <div class="menu-item"><a href="code.html">Codes & Data</a></div>
    <div class="menu-item"><a href="award.html">Awards & honours</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable" style="width: 100%">
        <tr valign="center">
            <td width="180"><img src="Tongliang-Liu.jpg" alt="Tongliang Liu" border="0" width=160/></td>
            <td align="left">
                <br>
                <p><span style="font-size: 110%"><b>Tongliang Liu</b></span></p>
                <p>
                    Associate Professor in Machine Learning<br>
                    Department of Machine Learning<br>
                    <a href="https://mbzuai.ac.ae/">Mohamed bin Zayed University of Artificial Intelligence</a>, United Arab Emirates<br>
                    </p>
                <p>
<!--                     Senior Lecturer in Machine Learning<br> -->
                    Director of <a HREF="https://www.sydney.edu.au/engineering/our-research/data-science-and-computer-engineering/ubtech-sydney-artificial-intelligence-centre.html"> Sydney AI Centre</a><br>
<!--                     Director of <a HREF="https://www.tmllab.ai/"> Trustworthy Machine Learning Lab (TML Lab)</a><br> -->
                    ARC Future Fellow; ARC DECRA Fellow (former)<br>
                    <a href="https://sydney.edu.au/engineering/about/school-of-computer-science.html" target="_blank">School of Computer Science</a><br>
                    <a href="https://www.sydney.edu.au/engineering/" target="_blank">Facult of Engineering</a><br>
                    <a href="https://sydney.edu.au/" target="_blank">The University of Sydney</a>, Australia
                </p>
                
<!--                 <p>
                    Visiting Scientist<br>
                    <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/?lang=en" target="_blank">Imperfect Information Learning Team</a><br>
                    <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, Japan<br>
                </p>
                
                  <p>
                    Visiting Professor<br>
                    <a href="https://iat.ustc.edu.cn/iat/index.html" target="_blank">Institute of Advanced Technology</a><br>
                    <a href="https://en.ustc.edu.cn/" target="_blank">Univeristy of Science and Technology of China</a>, China<br>
                </p> -->
                
<!--                 
                 <p>
                    Visiting Associate Professor<br>
                    <a href="https://mbzuai.ac.ae/research/department/machine-learning-department/" target="_blank">Machine Learning Department</a><br>
                    <a href="https://mbzuai.ac.ae/" target="_blank">Mohammed Bin Zayed University of Artificial Intelligence</a>, United Arab Emirates<br>
                </p>
 -->
                <p>
                    Address: Room 315/J12 1 Cleveland St, Darlington, NSW 2008, Australia <br>
                    E-mail: tongliang.liu [at] sydney.edu.au; tliang.liu [at] gmail.com<br>
                    <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                    <a href="https://dblp.uni-trier.de/pers/hd/l/Liu:Tongliang" target="_blank">[DBLP]</a>
                </p>
            </td>
            <td > </td>
<!--             <td align='right'>
                <table>
                    <tr><td height="20">&nbsp;</td><tr>
                    <tr><td align="center" style="text-align: center;"><img src="mit-book.jpeg" border="0" width=160/></td><tr>
                    <tr><td align="center" style="text-align: center;">Monograph on learning with noisy labels <br>by MIT Press. Coming in 2024!</td></tr>
                </table>
            </td> -->
            
                        <td align='right'>
                <table>
                    <tr><td height="20">&nbsp;</td><tr>
                    <tr><td align="center" style="text-align: center;"><b>Machine Learning with Noisy Labels</b></td><tr>
                    <tr><td align="center" style="text-align: center;">Monograph on learning with noisy labels <br>by MIT Press. Coming in 2024!</td></tr>
                </table>
            </td>
    </table>
    <p>Dr Tongliang Liu is currently working as an Associate Professor in Machine Learning with Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates. He is also the Director of Sydney AI Centre and a Senior Lecturer at University of Sydney, Australia; a Visiting Professor of University of Science and Technology of China, Hefei, China; a Visiting Scientist of RIKEN AIP, Tokyo, Japan.</p>
    
    <p>Dr Tongliang Liu works as a Future Fellow of  the Australian Research Council (ARC). He has been widely recognised by his research. For example, he was ranked among the Best Rising Stars of Science in Australia by Research.com in 2022; he was ranked among the Global Top Young Chinese Scholars in AI by Baidu Scholar in 2022;
he was named in the Early Achievers Leaderboard by The Australian in 2020.
He was the senior meta-reviewer of AAAI and IJCAI and is regularly the meta-reviewer of ICML, NeurIPS, ICLR, AAAI, and IJCAI. He is the Action Editor of Transactions on Machine Learning Research, Associate Editor of ACM Computing Surveys, and in the Editorial Board of Journal of Machine Learning Research and the Machine Learning journal.</p>

<p>His research interests lie in providing mathematical and theoretical foundations to justify and understand (deep) machine learning models and designing efficient learning algorithms for problems in computer vision and data mining, with a particular emphasis on
     <ul>
        <li><p>Learning with noisy labels</p></li>
               <li><p>Deep adversarial learning </p></li>
                      <li><p>Causal representation learning</p></li>
               <li><p>Deep transfer learning</p></li>
        <li><p>Deep unsupervised learning </p></li>
        <li><p>Statistical deep learning theory </p></li>
       </ul>
    </p>
    
    <!--     <p>I am currently a Senior Lecturer and director of the <a HREF="https://www.tmllab.ai/"> Trustworthy Machine Learning Lab (TML Lab)</a> with School of Computer Science at the University of Sydney. I am also a Visiting Scientist at <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, Japan. I received my PhD from the University of Technology Sydney and my BEng from the University of Science and Technology of China. </p> -->
    
<!--     <p>I am a recipient of Discovery Early Career Researcher Award (DECRA) from Australian Research Council (ARC); the Cardiovascular Initiative Catalyst Award by the Cardiovascular Initiative; and was named in the Early Achievers Leadboard of Engineering and Computer Science by The Australian in 2020.</p> -->
        
<!--     <p>Trustworthy Machine Learning Lab (TML Lab) at the University of Sydney hosts, attracts, and connects the best global talents to develop trustworthy machine learning techniques and tools, which are explainable, robust, fair, causally responsible, and privacy-preserving. Our mission is to make machines trustworthy, which is a foundation for our society to develop and deploy artificial intelligence to improve our lives. We are broadly interested in the fields of trustworthy machine learning and its interdisciplinary applications, with a particular emphasis on learning with noisy labels, adversarial learning, transfer learning, unsupervised learning, and statistical deep learning theory.  -->
        </p>
    
    <p><font color="#FF0000"> We are recruiting <b>PhD</b> and <b>visitors</b>. If you are interested, please send me your CV and transcripts.<br> </font></p >

<!--          <p><font color="#FF0000">
         <pp>
    <b>Postdoc positions</b> are available with competitive salary packages.          
    </pp>
          </font></p> -->
<!--     <p>
    <pp>  
     We are always looking for highly-motivated undergraduate and postgraduate students to join our group. Full scholarships are available!
   </pp>
   </p>
     -->

    
<!--       <p>
      A few visiting positions in machine learning and computer vision are available.
      </p> -->

<!--      Some information about scholarships: <ul>
     <li>For both domestic and international PhD students, you can apply for <a HREF="https://sydney.edu.au/scholarships/international/postgraduate-research.html">the RTP scholarship or the Faculty scholarship.</a> There is no specific deadline for the application. I would help you assess the probability to get a scholarship.</li> 
     <li>For international PhD students, you can also consider applying for some <a href="https://sydney.edu.au/scholarships/international/postgraduate-research/general.html"> general scholarships </a>. There are strict deadlines for the scholarships. For example, the <a href="https://sydney.edu.au/scholarships/e/china-scholarship-council-research-programs-scholarship.html"> CSC-USYD</a> scholarship has a deadline normally in December.</li>
     <li>For all students, there are also many other scholarships to explore. I am happy to supervise outstanding students who have passion in research.</li>
      </ul> -->
<!--     <div>
        <h2><hr><a name="news"></a>Research Interests</h2>
        My research interests lie in providing mathematical and theoretical foundations to justify and understand (deep) machine learning models and designing efficient learning algorithms for problems in computer vision and data mining, with a particular emphasis on 
   <ul>
        <li><p>Learning with noisy labels</p></li>
               <li><p>Deep adversarial learning </p></li>
                      <li><p>Causal representation learning</p></li>
               <li><p>Deep transfer learning</p></li>
        <li><p>Deep unsupervised learning </p></li>
        <li><p>Statistical deep learning theory </p></li>
       </ul>
     <div> -->
        <h2><hr><a name="news"></a>Top News</h2>
        <ul>                                         
            
            <li><p>09/2022, I was selected as an Australian Research Council Future Fellow<br> (only three researchers across Australia was awarded in the field of Information and Computing Sciences in 2022). </p></li>
                                        <li><p>09/2022, I was appointed as a Visiting Professor with University of Science and Technology of China. </p></li>
                            <li><p>09/2022, I was appointed as a Visiting Associate Professor with Mohammed Bin Zayed University of Artificial Intelligence. </p></li>
                            <li><p>08/2022, I accepted the invitation to serve as an Area Chair for ICLR 2023. </p></li>
                          <li><p>08/2022, I am in the editorial board of <a href="https://www.jmlr.org/editorial-board.html">JMLR</a>. </p></li>
              <li><p>08/2022, I was elected as one of the editorial board of the <a href="https://www.springer.com/journal/10994/editors">ML</a> journal. </p></li>
                        <li><p>08/2022, Two of my PhD students have got Google PhD Fellowship Awards. Congrats Xiaobo and Shuo! </p></li>
            <li><p>07/2022, I accepted the invitation to serve as a Discussant for UAI 2022.  </p></li>
                            <li><p>04/2022, I served as a Session Chair for ICLR 2022.  </p></li>
              <li><p>04/2022, I was selected as one of Global Top Young Chinese Scholars in AI by Baidu Scholar 2022.
                <li><p>03/2022, I will co-organize <a href="http://competition.noisylabels.com/">IJCAI 2022 Challenge on Learning with Noisy Labels</a>.  </p></li>
                            <li><p>03/2022, I accepted the invitation to serve as an Area Chair for NeurIPS 2022.  </p></li>
                <li><p>02/2022, my student James Wood got the University Medal! Congrats James! </p></li>
                <li><p>02/2022, my <a href="https://mitpress.mit.edu/books/series/adaptive-computation-and-machine-learning-series">monograph</a> on learning with noisy labels has been accepted by MIT Press. </p></li>
                <li><p>01/2022, I am invited to be an Action Editor of <a href="https://www.jmlr.org/tmlr/">TMLR</a>. </p></li>
<!--                 <li><p>01/2022, I accepted the invitation to serve as an Area Chair for ICPR 2022.  </p></li> -->
<!--                 <li><p>12/2021, ARC discovery project 2022 on Causally Responsible Transfer Learning (myself is the lead CI) has been funded. </p></li> -->
                <li><p>12/2021, I received the Faculty Early Career Research Excellence Award, University of Sydney.  </p></li>
                <li><p>12/2021, I accepted the invitation to serve as an Area Chair for ICML 2022. </p></li>
<!--                 <li><p>12/2021, I accepted the invitation to serve as an Meta Reviewer for ACM KDD 2022.  </p></li> -->
                <li><p>11/2021, I accepted the invitation to serve as an Area Chair for UAI 2022. </p></li>
                <li><p>07/2021, I accepted the invitation to serve as an Area Chair for AAAI 2022.  </p></li>
                <li><p>06/2021, I accepted the invitation to serve as an Area Chair for ICLR 2022.  </p></li>
<!--                 <li><p>04/2021, we are organising a Learning with Noisy Supervision <a href="https://wsl-workshop.github.io/ijcai21-tutorial"> tutorial </a> at IJCAI 2021. </p></li> -->
<!--                 <li><p>03/2021, we are organising a Weakly Supervised Representation Learning  <a href="https://wsl-workshop.github.io/ijcai21.html"> workshop </a> at IJCAI 2021.  </p></li> -->
                <li><p>04/2021, we are organising a <a href="https://wsl-workshop.github.io/MLJ_WSRL_CFP.pdf"> speical issue </a> at the <a href="https://www.springer.com/journal/10994"> ML</a> Journal.</p></li>

                <li><p>03/2021, I accepted the invitation to serve as an Area Chair for NeurIPS 2021.  </p></li>

                <li><p>02/2021, we are organising <a href="https://ajml2021.github.io/"> the first Australia-Japan Workshop on Machine Learning</a>.  </p></li>                        
                <li><p>9/2020, I was named in the Early Achievers Leaderboard by <a href="https://specialreports.theaustralian.com.au/1540291/27/">The Australian</a>.  </p></li>      
                <li><p>8/2020, I accepted the invitation to serve as an Area Chair for IJCAI 2021.  </p></li>

<!--                 <li><p>4/2020, I was appointed as a visiting scientist with RIKEN, Japan.  </p></li> -->
                
         </ul>
         See more previous news <a href="news.html">here</a>.
</div>
                          
  
                 <div>
        <h2><hr><a name="news"></a>Selected Publications on Learning with Noisy Labels</h2>
              <ul>
                  
                <li><p>
                MSR: Making Self-supervised learning Robust to Aggressive Augmentations. [<A >PDF</A>]<br>
                Y. Bai, E. Yang, Z. Wang, Y. Du, B. Han, C. Deng, D. Wang, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Estimating Noise Transition Matrix with Label Cor- relations for Noisy Multi-Label Learning. [<A >PDF</A>]<br>
                S. Li, X. Xia, H. Zhang, Y. Zhan, S. Ge, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                           
                <li><p>
                Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization. [<A >PDF</A>]<br>
                D. Cheng, Y. Ning, N. Wang, X. Gao, H. Yang, Y. Du, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
                </p></li>
                  
                <li><p>
                Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network. [<A >PDF</A>] [<a href="https://github.com/ShuoYang-1998/BLTM">CODE</a>]<br>
                S. Yang, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                  
               <li><p>
               Selective-Supervised Contrastive Learning with Noisy Labels. [<A href="https://arxiv.org/abs/2203.04181">PDF</A>] [<A href="https://github.com/ShikunLi/Sel-CL">CODE</A>] <br>
               S. Li, X. Xia, S. Ge, and <b>T. Liu</b>.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
                  
               
               <li><p>
               Instance-Dependent Label-Noise Learning With Manifold-Regularized Transition Matrix Estimation. [PDF] [<A href="https://github.com/Hao-Ning/MEIDTM-Instance-Dependent-Label-Noise-Learning-with-Manifold-Regularized-Transition-Matrix-Estimatio">CODE</A>] <br>
               D. Cheng, <b>T. Liu</b>, Y. Ning, N. Wang, B. Han, G. Niu, X. Gao, and M. Sugiyama.<br>
               In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
               </p></li>
                  
               <li><p>
               Rethinking Class-Prior Estimation for Positive-Unlabeled Learning. [<A HREF="https://openreview.net/forum?id=aYAA-XHKyk&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/a5507203/Rethinking-Class-Prior-Estimation-for-Positive-Unlabeled-Learning">CODE</a>] <br>
               Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, G. Niu, M. Sugiyama, and Dacheng Tao<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
            
            
               <li><p>
               Sample Selection with Uncertainty of Losses for Learning with Noisy Labels. [<A HREF="https://openreview.net/forum?id=xENf4QUL4LW&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/xiaoboxia/CNLCU">CODE</a>] <br>
               X. Xia, <b>T. Liu</b>, B. Han, M. Gong, J. Yu, G. Niu, and M. Sugiyama<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
                  
            <li><p>
           Me-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Bai_Me-Momentum_Extracting_Hard_Confident_Examples_From_Noisily_Labeled_Data_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/Me-Momentum">CODE</a>] [<font color="red">Oral</font>] <br>
           Y. Bai and <b>T. Liu</b><br>
           In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
           </p></li>
                  
            <li><p>
            Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] [<a href="https://github.com/a5507203/IDLN">CODE</a>]<br>
            Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
                  
            <li><p>
            Understanding and Improving Early Stopping for Learning with Noisy Labels. [<A HREF="https://arxiv.org/abs/2106.15853">PDF</A>] [<a href="https://github.com/tmllab/PES">CODE</a>]<br>
            Y, Bai, E. Yang, B. Han, Y. Yang, J. Li, Y. Mao, G. Niu, and <b>T. Liu</b>.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
        
           
           <li><p>
           Provably End-to-end Label-noise Learning without Anchor Points [<A HREF="https://arxiv.org/pdf/2102.02400.pdf">PDF</A>] [<A HREF="https://github.com/xuefeng-li1/Provably-end-to-end-label-noise-learning-without-anchor-points">CODE</A>]<br>
           X. Li, <b>T. Liu</b>, B. Han, G. Niu, and M. Sugiyama<br>
           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
           </p></li>           
            
           <li><p>
           Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels [<A HREF="http://proceedings.mlr.press/v139/wu21f/wu21f.pdf">PDF</A>] [<A HREF="https://github.com/scifancier/Class2Simi">CODE</A>] <br>
           S. Wu*, X. Xia*, <b>T. Liu</b>, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu <br>
           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
           </p></li>
                  
           <li><p>
           A Second-Order Approach to Learning with Instance-Dependent Label Noise. [<A HREF="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.pdf">PDF</A>] [<A HREF="https://github.com/UCSC-REAL/CAL">CODE</A>] [<font color="red">Oral</font>] <br>
           Z. Zhu, <b>T. Liu</b>, and Y. Liu.<br>
           In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
           </p></li>
                  
            <li><p>
            Robust early-learning: Hindering the memorization of noisy labels. [<A HREF="https://openreview.net/forum?id=Eql5b1_hTE4">PDF</A>] [<A HREF="https://github.com/xiaoboxia/CDR">CODE</A>]<br>
            X. Xia, <b>T. Liu</b>, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
            In <a href="https://iclr.cc/Conferences/2021"> ICLR</a>, 2021.
            </p></li>

             <li><p>
            Part-dependent Label Noise: Towards Instance-dependent Label Noise. [<A HREF="https://arxiv.org/abs/2006.07836">PDF</A>] [<a href="https://github.com/xiaoboxia/Part-dependent-label-noise">CODE</a>] [<font color="red">Spotlight</font>] <br>
            X. Xia, <b>T. Liu</b>, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
           
                  
            <li><p>
            Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. [<A HREF="https://arxiv.org/abs/2006.07805">PDF</A>] [<a href="https://github.com/a5507203/dual-T-Estimator">CODE</a>]<br>
            Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
                  
            
             <li><p>
            Learning with Bounded Instance- and Label-dependent Label Noise. [<A HREF="https://arxiv.org/abs/1709.03768">PDF</A>] [<a href="https://github.com/JiachengCheng96/Learning-with-bounded-instance-and-label-dependent-label-noise">CODE</a>]<br>
            J. Cheng, <b>T. Liu</b>, K. Rao, and D. Tao.<br>
            In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
            
            
            <li><p>
            Are Anchor Points Really Indispensable in Label-Noise Learning? [<A HREF="https://papers.nips.cc/paper/8908-are-anchor-points-really-indispensable-in-label-noise-learning.pdf">PDF</A>] [<A HREF="https://github.com/xiaoboxia/T-Revision">CODE</A>]<br>
            X. Xia, <b>T. Liu</b>, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/">NeurIPS</a>, 2019.
            </p></li>
                  

                                    
            <li><p>
            Learning with Biased Complementary Labels. [<A HREF="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdf">PDF</A>] [<A HREF="code/Xiyu_eccv2018_backup.tar.gz">CODE</A>] [<font color="red">Oral</font>]<br>
            X. Yu, <b>T. Liu</b>, M. Gong, and D. Tao.<br>
            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
            </p></li>
                  
                  
                                 
             <li><p>
            Classification with Noisy Labels by Importance Reweighting. [<A HREF="https://arxiv.org/pdf/1411.7718.pdf">PDF</A>] [<A HREF="https://github.com/xiaoboxia/Classification-with-noisy-labels-by-importance-reweighting">CODE</A>]<br>
            <b>T. Liu</b> and D. Tao.<br>
            <b><i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i></b>, 38(3): 447-461, 2015.<br/>
            </p></li>
                  
                  
            </ul>
</div>
         
         
          <div>
        <h2><a name="news"></a>Selected Publications on Adversarial Learning</h2>
              <ul>
                  
                <li><p>
                Modeling Adversarial Noise for Adversarial Defense. [<A href="https://arxiv.org/abs/2109.09901">PDF</A>] [<a href="https://github.com/dwDavidxd/MAN">CODE</a>]<br>
                D. Zhou, N. Wang, B. Han, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                  
                <li><p>
                Improving Adversarial Robustness via Mutual Information Estimation. [<A >PDF</A>]<br>
                D. Zhou, N. Wang, X. Gao, B. Han, X. Wang, Y. Zhan, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
        
                           
                <li><p>
                Understanding Robust Overfitting of Adversarial Training and Beyond. [<A >PDF</A>] [<a href="https://github.com/ChaojianYu/Understanding-Robust-Overfitting">CODE</a>]<br>
                C. Yu, B. Han, L. Shen, J. Yu, C. Gong, M. Gong, and <b>T. Liu</b>.<br>
                In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
                </p></li>
                  
               <li><p>
               Adversarial Robustness Through the Lens of Causality. [<A HREF="https://openreview.net/forum?id=cZAi1yWpiXQ&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [CODE] <br>
               Y. Zhang, M. Gong, <b>T. Liu</b>, G. Niu, X. Tian, B. Han, B. Schölkopf, and K. Zhang<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
                  
            <li><p>
           Removing Adversarial Noise in Class Activation Feature Space [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Removing_Adversarial_Noise_in_Class_Activation_Feature_Space_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/dwDavidxd/CAFD">CODE</a>]<br>
           D. Zhou, N. Wang, C. Peng, X. Gao, X. Wang, J. Yu, <b>T. Liu</b><br>
           In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
           </p></li>  
                  
          <li><p>
           Towards Defending against Adversarial Examples via Attack-Invariant Features [<A HREF="https://arxiv.org/pdf/2106.05036.pdf">PDF</A>] [<a href="https://github.com/dwDavidxd/ARN">CODE</a>]<br>
           D. Zhou, <b>T. Liu</b>, B. Han, N. Wang, C. Peng, and X. Gao <br>
           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
           </p></li>     
                  
                  
<!--              <li><p>
            Probabilistic Margins for Instance Reweighting in Adversarial Training. [<A HREF="https://arxiv.org/abs/2106.07904">PDF</A>] [<a href="https://github.com/QizhouWang/MAIL?ref=pythonawesome.com">CODE</a>]<br>
            Q. Wang, F. Liu, B. Han, <b>T. Liu</b>, C. Gong, G. Niu, M. Zhou, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
                     
                        
            
           <li><p>
           Maximum Mean Discrepancy is Aware of Adversarial Attacks  [<A HREF="http://proceedings.mlr.press/v139/gao21b/gao21b.pdf">PDF</A>] [<a href="https://github.com/Sjtubrian/SAMMD">CODE</a>]<br>
           R. Gao, F. Liu, J. Zhang, B. Han, <b>T. Liu</b>, G. Niu, M. Sugiyama <br>
           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
           </p></li>
          
            
           <li><p>
           Learning Diverse-Structured Networks for Adversarial Robustness [<A HREF="https://arxiv.org/pdf/2102.01886.pdf">PDF</A>] [<a href="https://github.com/d12306/dsnet">CODE</a>]<br>
           X. Du, J. Zhang, B. Han, <b>T. Liu</b>, Y. Rong, G. Niu, J. Huang, and M. Sugiyama <br>
           In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
           </p></li> -->
                  
            <li><p>
            Dual-Path Distillation: A Unified Framework to Improve Black-Box Attacks. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Paper.pdf">PDF</A>] <br>
            Y. Zhang, Y. Li, <b>T. Liu</b>, and X. Tian.<br>
             In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
                  
              </ul>
</div>
            
    
<!--         
              <div>
        <h2><a name="news"></a>Selected Publications on Causal Representation Learning</h2>
              <ul>
                  
               <li><p>
               Adversarial Robustness Through the Lens of Causality. [<A HREF="https://openreview.net/forum?id=cZAi1yWpiXQ&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [CODE] <br>
               Y. Zhang, M. Gong, <b>T. Liu</b>, G. Niu, X. Tian, B. Han, B. Schölkopf, and K. Zhang<br>
               In <a href="https://iclr.cc/"> ICLR</a>, 2022.
               </p></li>
                  
               <li><p>
               Fair Classification with Instance-dependent Label Noise. [<A HREF="https://openreview.net/forum?id=s-pcpETLpY">PDF</A>] <br>
               S. Wu, M. Gong, B. Han, Y. Liu, and <b>T. Liu</b><br>
               In <a href="https://www.cclear.cc/"> CLeaR</a>, 2022.
               </p></li>
                 
            <li><p>
            Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] [<a href="https://github.com/a5507203/IDLN">CODE</a>]<br>
            Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
                       
                  
              </ul> -->
</div>
        
        
        
  
        
        <div>
        <h2><a name="news"></a>Selected Publications on Transfer Learning</h2>
              <ul>
                  
             
<!--                   <li><p>
            Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation.[<A HREF="https://ieeexplore.ieee.org/document/9204804">Paper</A>]<br>
           X. Yang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
            </p></li>   -->
                  
             <li><p>
            Confident-Anchor-Induced Multi-Source-Free Domain Adaptation. [<A HREF="https://papers.nips.cc/paper/2021/file/168908dd3227b8358eababa07fcaf091-Paper.pdf">PDF</A>] [<a href="https://github.com/Learning-group123/CAiDA">CODE</a>]<br>
            J. Dong, Z. Fang, A. Liu, G. Sun, and <b>T. Liu</b>.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
            
                  
                  
            <li><p>
            Domain Generalization via Entropy Regularization. [<A HREF="https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf">PDF</A>] [<a href="https://github.com/sshan-zhao/DG_via_ER">CODE</a>]<br>
            S. Zhao, M. Gong, <b>T. Liu</b>,  H. Fu, and D. Tao.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
                  
            
<!--             <li><p>
            Label-Noise Robust Domain Adaptation.<br>
            X. Yu, <b>T. Liu</b>, M. Gong, K. Zhang, K. Batmanghelich, and D. Tao.<br>
             In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li> -->
                  
             <li><p>
            Transferring Knowledge Fragments for Learning Distance Metric from A Heterogeneous Domain. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8333749">Paper</A>] [<a href="https://github.com/yluopku/GB-HTDML">CODE</a>]<br>
            Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(4): 1013-1026, 2019.<br/>
            </p></li>
            
                  
            <li><p>
            LTF: A Label Transformation Framework for Correcting Label Shift. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf">PDF</A>] [<a href="https://github.com/CR-Gjx/LTF-Label-Transformation-Framework">CODE</a>]<br>
            J. Guo, M. Gong, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
             In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
                  
            <li><p>
            Deep Domain Generalization via Conditional Invariant Adversarial Networks. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ya_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdf">PDF</A>] [<a href="http://staff.ustc.edu.cn/~xinmei/publications_pdf/2018/code-YaLi.zip">CODE</a>]<br>
            Y. Li, X. Tian, M. Gong, Y. Liu, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
            </p></li>
                  
            <li><p>
            Understanding How Feature Structure Transfers in Transfer Learning. [<A HREF="https://www.ijcai.org/Proceedings/2017/0329.pdf">PDF</A>]<br>
            <b>T. Liu</b>, Q. Yang, and D. Tao.<br>
            In <a href="https://ijcai-17.org/"> IJCAI</a>, 2017.
            </p></li>

            <li><p>
            Domain Adaptation with Conditional Transferable Components. [<A HREF="http://proceedings.mlr.press/v48/gong16.pdf">PDF</A>] [<A HREF="code/CTC.zip">CODE</A>]<br>
            M. Gong, K. Zhang, <b>T. Liu</b>, D. Tao, C. Glymour, and B. Schölkopf.<br>
            In <a href="http://icml.cc/2016/"> ICML</a></i>, 2106.
            </p></li>
                  
                  
              </ul>
</div>
        
        
  
        
        <div>
        <h2><a name="news"></a>Selected Publications on Statistical (Deep) Learning Theory</h2>
              <ul>
            <li><p>
            On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes Optimal Classifier. [<A HREF="https://arxiv.org/abs/1802.03688">PDF</A>]<br>
            J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, accepted 2021.<br/>
            </p></li>   
            
                  
            <li><p>
            Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence. [<A HREF="https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf">PDF</A>]<br>
            F. He, <b>T. Liu</b>, and D. Tao.<br>
            In <a href="https://nips.cc/">NeurIPS</a></i>, 2019.
            </p></li>
        
        
            <li><p>
            Algorithmic Stability and Hypothesis Complexity. [<A HREF="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">PDF</A>]<br>
            <b>T. Liu</b>, G. Lugosi, G. Neu and D. Tao.<br>
            In <a href="https://2017.icml.cc/"> ICML </a>, 2017.
            </p></li>
               

                  
            <li><p>
            Algorithm-Dependent Generalization Bounds for Multi-Task Learning. [<A HREF="https://ieeexplore.ieee.org/document/7437460">Paper</A>]<br>
            <b>T. Liu</b>, D. Tao, M. Song, and S. J. Maybank.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 39(2): 227-241, 2017.<br/>
            </p></li>
        

                  
                  
              </ul>
See more publications <a href="publications.html">here</a>.
</div>



        
     <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
         <p>
                 <img class="center" src="arc sponsor.png" alt="Australian Research Council" width="200" height="50"/>
                 <img class="center" src="usyd sponsor.png" alt="Usyd" width="150" height="50"/>
                 <img class="center" src="CVI.jpeg" alt="CVI" width="150" height="90"/>
                 <img class="center" src="CPA.png" alt="CPA" width="150" height="80"/>
                 <img class="center" src="Meituan_English_Logo.png" alt="Meituan" width="150" height="40"/>
                 <img class="center" src="logo_NSSN.png" alt="NSSN" width="150" height="50"/>
                 <img class="center" src="logo-intelicare.png" alt="InteliCare" width="150" height="70"/>
                 <img class="center" src="logo-ZhanDa.jpeg" alt="ZhanDa" width="150" height="90"/>
                 <img class="center" src="jd.com.jpeg" alt="JD" width="125" height="90"/>
                 <img class="center" src="Riken-aip.jpeg" alt="RIKEN" width="170" height="90"/>
                 <img class="center" src="oppologo.png" alt="OPPO" width="150" height="50"/>
                 <img class="center" src="mbzuai_logo.png" alt="MBZUAI" width="245" height="61"/>

</p>
    </div>
        
<div>

      <h2 style="font-family: Helvetica,Arial,sans-serif;"><o:p>&nbsp;</o:p></h2>
      <p>
<!--         Last Update: 5/2019.<br> -->
    <script src="//t1.extreme-dm.com/f.js" id="eXF-tliu9526-0" async defer></script>

   
</p>
</div>

</td>
</tr>
</table>
</body>
</html>
