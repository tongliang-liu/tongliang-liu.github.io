
<html>

<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="shortcut icon" href="paper_dragon.ico">
<link rel="stylesheet" type="text/css" href="style.css" />
<!-- <link rel="shortcut icon" href="paper_dragon.ico"> -->
<title>Tongliang Liu's Homepage </title>
<!-- <base href="https://tongliang-liu.github.io/index.html"> -->
<!-- <base href="./index.html"> -->

<script type="text/javascript" src="//ra.revolvermaps.com/0/0/8.js?i=0gh03rwju0o&amp;m=0&amp;s=170&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;v0=80" async="async"></script>
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Tongliang Liu</h1><hr>
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="groups.html">Group</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="grants.html">Grants</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="code.html">Codes & Data</a></div>
<div class="menu-item"><a href="award.html">Awards & honours</a></div>
</td>
<td id="layout-content">

<h1 style="margin-top: 0em">Home</h1><br>

<table class="imgtable" style="width: 100%">
    <tr valign="center">
        <td width="180"><img src="Tongliang-Liu.jpg" alt="Tongliang Liu" border="0" width=160/></td>
        <td align="left">
            <br>
            <p><span style="font-size: 110%"><b>Tongliang Liu</b></span></p>

            <p>
<!--                     Senior Lecturer in Machine Learning<br> -->
                Director of <a HREF="https://www.sydney.edu.au/engineering/our-research/data-science-and-computer-engineering/ubtech-sydney-artificial-intelligence-centre.html" target="_blank" > Sydney AI Centre</a><br>
                Deputy Associate Head of School for Research<br>
                Co-Editor-in-Chief of <a href="https://www.sciencedirect.com/journal/neural-networks" target="_blank" >Neural Networks</a><br>
                (JCR Q1, Chinese Academy of Sciences ranking Q1, CORE A, and CCF B)<br>
                Program Chair of the <a href="https://ajcai2023.org/" target="_blank">36th Australasian Joint Conference on AI</a><br>
<!--                 Director of <a HREF="https://www.tmllab.ai/" target="_blank"> Trustworthy Machine Learning Lab (TML Lab)</a><br> -->
                ARC Future Fellow; ARC DECRA Fellow<br>
                <a href="https://sydney.edu.au/engineering/about/school-of-computer-science.html" target="_blank">School of Computer Science</a><br>
                <a href="https://www.sydney.edu.au/engineering/" target="_blank">Facult of Engineering</a><br>
                <a href="https://sydney.edu.au/" target="_blank">The University of Sydney</a>, Australia
            </p>
            
<!--                 <p>
                Visiting Associate Professor in Machine Learning<br>
                Department of Machine Learning<br>
                <a href="https://mbzuai.ac.ae/" target="_blank" >Mohamed bin Zayed University of Artificial Intelligence</a>, United Arab Emirates<br>
            </p>  
            
            <p>
                Visiting Scientist<br>
                <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/?lang=en" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, Japan<br>
            </p>
            
            <p>
                Visiting Professor<br>
                <a href="https://iat.ustc.edu.cn/iat/index.html" target="_blank">Institute of Advanced Technology</a><br>
                <a href="https://en.ustc.edu.cn/" target="_blank">Univeristy of Science and Technology of China</a>, China<br>
            </p> -->
            
            
<!--                  <p>
                Visiting Associate Professor<br>
                <a href="https://mbzuai.ac.ae/research/department/machine-learning-department/" target="_blank">Machine Learning Department</a><br>
                <a href="https://mbzuai.ac.ae/" target="_blank">Mohammed Bin Zayed University of Artificial Intelligence</a>, United Arab Emirates<br>
            </p> -->

            <p>
                Address: Room 315/J12 1 Cleveland St, Darlington, NSW 2008, Australia <br>
                E-mail: tongliang.liu [at] sydney.edu.au; tliang.liu [at] gmail.com<br>
                <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                <a href="https://dblp.uni-trier.de/pers/hd/l/Liu:Tongliang" target="_blank">[DBLP]</a>
            </p>
        </td>
        
        <td > </td>

        
        <td align='right'>
            <table>
                <tr><td height="20">&nbsp;</td><tr>
                <tr><td align="center" style="text-align: center;"><b>Machine Learning with Noisy Labels</b></td><tr>
                <tr><td align="center" style="text-align: center;">Monograph on learning with noisy labels <br>by MIT Press. Coming in 2024!</td></tr>
            </table>
        </td>
</table>

<h2><hr><a name="news"></a>Short Bio</h2>   

<p>Tongliang Liu has published more than 200 papers at leading ML/AI conferences and journals.
<!--    He has been widely recognised by his research. For example, he was ranked among the Best Rising Stars of Science in Australia by Research.com in 2022; he was ranked among the Global Top Young Chinese Scholars in AI by Baidu Scholar in 2022; -->
<!-- he was named in the Early Achievers Leaderboard by The Australian in 2020.  -->
    He received the CORE Award for Outstanding Research Contribution in 2024, IEEE AI's 10 to Watch Award in 2023, Eureka Prize shortlist for Emerging Leader in Science in 2023, ARC Future Fellowship Award in 2022, Faculty Early Career Research Excellence Award in 2021, the Top-40 Early Achievers by The Australian in 2020, and the ARC DECRA Award in 2018.
    He also received multiple faculty awards, e.g., from OPPO and Meituan.
    Tongliang is also very proud of his talented students, who have made/are making/will make significant contributions to advancing science. They have also been recognised by many awards, e.g., Google PhD Fellowship Awards.

<p>Tongliang Liu is the Director of Sydney AI Centre and an Associate Professor at The University of Sydney, Australia; an Affiliated Associate Professor in Machine Learning with Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates; a Visiting Professor of University of Science and Technology of China, Hefei, China; a Visiting Scientist of RIKEN AIP, Tokyo, Japan.</p>

<p>His research interests lie in providing mathematical and theoretical foundations to justify and understand machine learning models and designing efficient learning algorithms for problems in the field of trustworthy machine learning, with a particular emphasis on
<ul>
    <li><p>Learning with noisy labels,</p></li>
    <li><p>Deep adversarial learning, </p></li>
    <li><p>Causal representation learning,</p></li>
    <li><p>Deep transfer learning,</p></li>
    <li><p>Deep unsupervised learning, </p></li>
    <li><p>Statistical deep learning theory. </p></li>
</ul>
He is a Co-Editor-in-Chief of Neural Networks. He is regularly the meta-reviewer of ICML, NeurIPS, ICLR, UAI, IJCAI, and AAAI. He is an Action Editor of Transactions on Machine Learning Research, an Associate Editor of ACM Computing Surveys, and on the Editorial Board of Journal of Machine Learning Research and the Machine Learning journal.</p>

</p>
    
<!--     <p>Trustworthy Machine Learning Lab (TML Lab) at the University of Sydney hosts, attracts, and connects the best global talents to develop trustworthy machine learning techniques and tools, which are explainable, robust, fair, causally responsible, and privacy-preserving. Our mission is to make machines trustworthy, which is a foundation for our society to develop and deploy artificial intelligence to improve our lives. We are broadly interested in the fields of trustworthy machine learning and its interdisciplinary applications, with a particular emphasis on learning with noisy labels, adversarial learning, transfer learning, unsupervised learning, and statistical deep learning theory.  -->
</p>

<!-- <p><font color="#FF0000"> We are recruiting <b>PhD</b> and <b>visitors</b>. If you are interested, please send me your CV and transcripts.<br> </font></p > -->
<p><font color="#FF0000"> We are looking for visiting scholars for <b>Asian Trustworthy Machine Learning (ATML) Fellowships</b>. See more details <a href="https://tongliang-liu.github.io//atml_fellowships_2023.pdf">here</a>.<br> </font></p >

<!--          <p><font color="#FF0000">
     <pp>
<b>Postdoc positions</b> are available with competitive salary packages.          
</pp>
      </font></p> -->
<!--       <p>
  A few visiting positions in machine learning and computer vision are available.
  </p> -->

<!--      Some information about scholarships: <ul>
 <li>For both domestic and international PhD students, you can apply for <a HREF="https://sydney.edu.au/scholarships/international/postgraduate-research.html">the RTP scholarship or the Faculty scholarship.</a> There is no specific deadline for the application. I would help you assess the probability to get a scholarship.</li> 
 <li>For international PhD students, you can also consider applying for some <a href="https://sydney.edu.au/scholarships/international/postgraduate-research/general.html"> general scholarships </a>. There are strict deadlines for the scholarships. For example, the <a href="https://sydney.edu.au/scholarships/e/china-scholarship-council-research-programs-scholarship.html"> CSC-USYD</a> scholarship has a deadline normally in December.</li>
 <li>For all students, there are also many other scholarships to explore. I am happy to supervise outstanding students who have passion in research.</li>
  </ul> -->
<!--     <div>
    <h2><hr><a name="news"></a>Research Interests</h2>
    My research interests lie in providing mathematical and theoretical foundations to justify and understand (deep) machine learning models and designing efficient learning algorithms for problems in computer vision and data mining, with a particular emphasis on 
<ul>
    <li><p>Learning with noisy labels</p></li>
           <li><p>Deep adversarial learning </p></li>
                  <li><p>Causal representation learning</p></li>
           <li><p>Deep transfer learning</p></li>
    <li><p>Deep unsupervised learning </p></li>
    <li><p>Statistical deep learning theory </p></li>
   </ul>
 <div> -->


<!-- <h2><hr><a name="news"></a>Job Experience</h2>

<table class="imgtable" style="width: 100%">
   
       
        <td align="left">
            <p>
            <b>
            2022 - </br>
            2020 - </br>
            2024 - </br>
            2024 - </br>
            2020 - </br>
            2022 - 2024</br>
            2022 - 2023</br>
            2022 - 2023</br>
            2017 - 2021</br>
            2016 - 2017
            </b>
            </p>
        </td>
        
        <td align="left">
            <p>
            Director of Sydney Artificial Intelligence Centre, The University of Sydney</br>
            Director of Trustworthy Machine Learning (TML) Lab, The University of Sydney</br>
            Associate Professor in Machine Learning, The University of Sydney</br>
            Affiliated Associate Professor, Mohamed Bin Zayed University of Artificial Intelligence, United Arab Emirates</br>
            Visiting Scientist, RIKEN AIP, Japan</br>
            Visiting Professor, University of Science and Technology of China, China</br>
            Visiting Associate Professor, Mohamed Bin Zayed University of Artificial Intelligence, United Arab Emirates</br>
            Senior Lecturer, The University of Sydney</br>
            Lecturer, The University of Sydney</br>
            Lecturer, University of Technology Sydney
            </p>
        </td>         
</table>
 -->
    <h2><hr><a name="news"></a>Top News</h2>
    <ul> 
        <li><p>02/2024, I am honoured to be named an AI Future Leader by AI Magazine: <a href="https://aimagazine.com/top10/top-10-future-ai-leaders">"Top 10: Future AI Leaders"</a>. </p></li>
        <li><p>12/2023, I am a notable Area Chair for NeurIPS 2023. </p></li>
        <li><p>12/2023, I am honoured to receive the <a href="https://www.core.edu.au/awards">CORE Award for Outstanding Research Contribution</a>. </p></li>
        <li><p>11/2023, my student Muyang Li Received the Best Poster Award in ML and AI from the School of Computer Science! Congrats Muyang! </p></li>
        <li><p>09/2023, my student Yang Zhou got the University Medal! Congrats Yang! </p></li>
        <li><p>09/2023, my student Junzhi Ning got the University Medal! Congrats Junzhi! </p></li>
        <li><p>07/2023, my student Jiacheng Zhang got the University Medal! Congrats Jiacheng! </p></li>
            <li><p>07/2023, I am honoured to be shortlist for the <a href="https://australian.museum/get-involved/eureka-prizes/eureka-prizes-archive/2023-eureka-prizes-finalists/">Eureka Prize for Emerging Leader in Science</a>. </p></li>
<!--         <li><p>05/2023, I accepted the invitation to serve as an Area Chair for AAAI 2024. </p></li> -->
        <li><p>05/2023, I am honoured to receive the <a href="https://www.computer.org/publications/tech-news/insider/2022-ais-top-10-to-watch">IEEE AI's 10 to Watch Award</a> by the IEEE Computer Society. [<a href="https://ieeexplore.ieee.org/document/10111517">PDF</a>] </p></li>
        <li><p>04/2023, We have organised the <a href="https://mbzuai.ac.ae/events/category/virtual/">MBZUAI-RIKEN AIP joint workshop on intelligent systems</a>. </p></li>
        <li><p>03/2023, my student Muyang Li got the Top Final Year High Honour Roll! Congrats Muyang! </p></li>
        <li><p>03/2023, I am a notable Area Chair for ICLR 2023. </p></li>
<!--         <li><p>02/2023, I accepted the invitation to serve as an Area Chair for NeurIPS 2023. </p></li> -->
<!--         <li><p>12/2022, I accepted the invitation to serve as an Area Chair for ICML 2023. </p></li> -->
<!--         <li><p>12/2022, I accepted the invitation to serve as an Area Chair for UAI 2023. </p></li> -->
        <li><p>09/2022, I was selected as an Australian Research Council Future Fellow<br> (only three researchers across Australia was awarded in the field of Information and Computing Sciences in 2022). </p></li>
        <li><p>09/2022, I was appointed as a Visiting Professor with University of Science and Technology of China. </p></li>
        <li><p>09/2022, I was appointed as a Visiting Associate Professor with Mohammed Bin Zayed University of Artificial Intelligence. </p></li>
<!--         <li><p>08/2022, I accepted the invitation to serve as an Area Chair for ICLR 2023. </p></li> -->
        <li><p>08/2022, I am in the editorial board of <a href="https://www.jmlr.org/editorial-board.html">JMLR</a>. </p></li>
        <li><p>08/2022, I was elected as one of the editorial board of the <a href="https://www.springer.com/journal/10994/editors">ML</a> journal. </p></li>
        <li><p>08/2022, Two of my PhD students have got Google PhD Fellowship Awards. Congrats Xiaobo and Shuo! </p></li>
<!--         <li><p>07/2022, I accepted the invitation to serve as a Discussant for UAI 2022.  </p></li> -->
<!--         <li><p>04/2022, I served as a Session Chair for ICLR 2022.  </p></li> -->
        <li><p>04/2022, I was selected as one of Global Top Young Chinese Scholars in AI by Baidu Scholar 2022.
        <li><p>03/2022, I will co-organize <a href="http://competition.noisylabels.com/">IJCAI 2022 Challenge on Learning with Noisy Labels</a>.  </p></li>
<!--         <li><p>03/2022, I accepted the invitation to serve as an Area Chair for NeurIPS 2022.  </p></li> -->
        <li><p>02/2022, my student James Wood got the University Medal! Congrats James! </p></li>
        <li><p>02/2022, my <a href="https://mitpress.mit.edu/books/series/adaptive-computation-and-machine-learning-series">monograph</a> on learning with noisy labels has been accepted by MIT Press. </p></li>
<!--         <li><p>01/2022, I am invited to be an Action Editor of <a href="https://www.jmlr.org/tmlr/">TMLR</a>. </p></li> -->
        <li><p>12/2021, I received the Faculty Early Career Research Excellence Award, University of Sydney.  </p></li>
<!--         <li><p>12/2021, I accepted the invitation to serve as an Area Chair for ICML 2022. </p></li> -->
<!--         <li><p>11/2021, I accepted the invitation to serve as an Area Chair for UAI 2022. </p></li> -->
<!--         <li><p>07/2021, I accepted the invitation to serve as an Area Chair for AAAI 2022.  </p></li> -->
<!--         <li><p>06/2021, I accepted the invitation to serve as an Area Chair for ICLR 2022.  </p></li> -->
        <li><p>04/2021, we are organising a <a href="https://wsl-workshop.github.io/MLJ_WSRL_CFP.pdf"> speical issue </a> at the <a href="https://www.springer.com/journal/10994"> ML</a> Journal.</p></li>
<!--         <li><p>03/2021, I accepted the invitation to serve as an Area Chair for NeurIPS 2021.  </p></li> -->
        <li><p>02/2021, we are organising <a href="https://ajml2021.github.io/"> the first Australia-Japan Workshop on Machine Learning</a>.  </p></li>                        
        <li><p>9/2020, I was named in the Early Achievers Leaderboard by <a href="https://specialreports.theaustralian.com.au/1540291/27/">The Australian</a>.  </p></li>      
<!--         <li><p>8/2020, I accepted the invitation to serve as an Area Chair for IJCAI 2021.  </p></li>             -->
     </ul>

     See more previous news <a href="news.html">here</a>.
</div>
            <div>
            <h2><hr><a name="news"></a>Selected Publications on Learning with Noisy Labels</h2>
            <ul>
            
            
               
            <li><p>
            Which is Better for Learning with Noisy Labels: The Semi-supervised Method or Modeling Label Noise? [<A href="https://proceedings.mlr.press/v202/yao23a/yao23a.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_Which-is-Better-for-Learning-with-Noisy-Labels">CODE</a>]<br>
            Y. Yao, M. Gong, Y. Du, J. Yu, B. Han, K. Zhang, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
            </p></li>  
            
            
            <li><p>
            RSA: Reducing Semantic Shift from Aggressive Augmentations for Self-supervised Learning. [<A href="https://openreview.net/pdf?id=Cgmk9CicWFl">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_RSA">CODE</a>]<br>
            Y. Bai, E. Yang, Z. Wang, Y. Du, B. Han, C. Deng, D. Wang, and <b>T. Liu</b>.<br>
            In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
            </p></li>
               
            <li><p>
            Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning. [<A href="https://openreview.net/pdf?id=GwXrGy_vc8m">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_Multi-Label-T">CODE</a>] [<font color="red">Spotlight</font>]<br>
            S. Li, X. Xia, H. Zhang, Y. Zhan, S. Ge, and <b>T. Liu</b>.<br>
            In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
            </p></li>
               
            <li><p>
            Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization. [<A href="https://openreview.net/pdf?id=IvnoGKQuXi">PDF</A>] [<a href="https://github.com/tmllab/2022_NeurIPS_Class-Dependent-Label-Noise-Learning-with-Cycle-Consistency-Regularization">CODE</a>]<br>
            D. Cheng, Y. Ning, N. Wang, X. Gao, H. Yang, Y. Du, B. Han, and <b>T. Liu</b>.<br>
            In <a href="https://neurips.cc/"> NeurIPS</a>, 2022.
            </p></li>
            
            <li><p>
            Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network. [<A href="https://proceedings.mlr.press/v162/yang22p/yang22p.pdf">PDF</A>] [<a href="https://github.com/ShuoYang-1998/BLTM">CODE</a>]<br>
            S. Yang, E. Yang, B. Han, Y. Liu, M. Xu, G. Niu, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
            </p></li>
            
            <li><p>
            Selective-Supervised Contrastive Learning with Noisy Labels. [<A href="https://arxiv.org/abs/2203.04181">PDF</A>] [<A href="https://github.com/tmllab/2022_CVPR_Sel-CL">CODE</A>] <br>
            S. Li, X. Xia, S. Ge, and <b>T. Liu</b>.<br>
            In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
            </p></li>
            
            
            <li><p>
            Instance-Dependent Label-Noise Learning With Manifold-Regularized Transition Matrix Estimation. [<a href="https://arxiv.org/pdf/2206.02791.pdf">PDF</a>] [<A href="https://github.com/tmllab/2022_CVPR_MEIDTM">CODE</A>] <br>
            D. Cheng, <b>T. Liu</b>, Y. Ning, N. Wang, B. Han, G. Niu, X. Gao, and M. Sugiyama.<br>
            In <a href="http://cvpr2022.thecvf.com/"> CVPR</a>, 2022.
            </p></li>
            
            <li><p>
            Rethinking Class-Prior Estimation for Positive-Unlabeled Learning. [<A HREF="https://openreview.net/forum?id=aYAA-XHKyk&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/tmllab/2022_ICLR_Rethinking-Class-Prior-Estimation-for-Positive-Unlabeled-Learning">CODE</a>] <br>
            Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, G. Niu, M. Sugiyama, and Dacheng Tao<br>
            In <a href="https://iclr.cc/"> ICLR</a>, 2022.
            </p></li>
            
            
            <li><p>
            Sample Selection with Uncertainty of Losses for Learning with Noisy Labels. [<A HREF="https://openreview.net/forum?id=xENf4QUL4LW&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/tmllab/2022_ICLR_CNLCU">CODE</a>] <br>
            X. Xia, <b>T. Liu</b>, B. Han, M. Gong, J. Yu, G. Niu, and M. Sugiyama<br>
            In <a href="https://iclr.cc/"> ICLR</a>, 2022.
            </p></li>
            
            <li><p>
            Me-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Bai_Me-Momentum_Extracting_Hard_Confident_Examples_From_Noisily_Labeled_Data_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/Me-Momentum">CODE</a>] [<font color="red">Oral</font>] <br>
            Y. Bai and <b>T. Liu</b><br>
            In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
            </p></li>
            
            <li><p>
            Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] [<a href="https://github.com/tmllab/2021_NeurIPS_Instance-dependent-Label-noise-Learning-under-a-Structural-Causal-Model">CODE</a>]<br>
            Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
            
            <li><p>
            Understanding and Improving Early Stopping for Learning with Noisy Labels. [<A HREF="https://arxiv.org/abs/2106.15853">PDF</A>] [<a href="https://github.com/tmllab/PES">CODE</a>]<br>
            Y, Bai, E. Yang, B. Han, Y. Yang, J. Li, Y. Mao, G. Niu, and <b>T. Liu</b>.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
            </p></li>
            
            
            <li><p>
            Provably End-to-end Label-noise Learning without Anchor Points. [<A HREF="https://arxiv.org/pdf/2102.02400.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICML_Provably-end-to-end-label-noise-learning-without-anchor-points">CODE</A>]<br>
            X. Li, <b>T. Liu</b>, B. Han, G. Niu, and M. Sugiyama<br>
            In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
            </p></li>           
            
            <li><p>
            Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels. [<A HREF="http://proceedings.mlr.press/v139/wu21f/wu21f.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICML_Class2Simi">CODE</A>] <br>
            S. Wu*, X. Xia*, <b>T. Liu</b>, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu <br>
            In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
            </p></li>
            
            <li><p>
            A Second-Order Approach to Learning with Instance-Dependent Label Noise. [<A HREF="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.pdf">PDF</A>] [<A HREF="https://github.com/UCSC-REAL/CAL">CODE</A>] [<font color="red">Oral</font>] <br>
            Z. Zhu, <b>T. Liu</b>, and Y. Liu.<br>
            In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
            </p></li>
            
            <li><p>
            Robust early-learning: Hindering the memorization of noisy labels. [<A HREF="https://openreview.net/forum?id=Eql5b1_hTE4">PDF</A>] [<A HREF="https://github.com/tmllab/2021_ICLR_CDR">CODE</A>]<br>
            X. Xia, <b>T. Liu</b>, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
            In <a href="https://iclr.cc/Conferences/2021"> ICLR</a>, 2021.
            </p></li>
            
            <li><p>
            Part-dependent Label Noise: Towards Instance-dependent Label Noise. [<A HREF="https://arxiv.org/abs/2006.07836">PDF</A>] [<a href="https://github.com/tmllab/2020_NeurIPS_PTD">CODE</a>] [<font color="red">Spotlight</font>] <br>
            X. Xia, <b>T. Liu</b>, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
            
            
            <li><p>
            Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. [<A HREF="https://arxiv.org/abs/2006.07805">PDF</A>] [<a href="https://github.com/tmllab/2020_NeurIPS_dual-t-reducing-estimation-error-for-transition-matrix-in-label-noise-learning">CODE</a>]<br>
            Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
            
            
            <li><p>
            Learning with Bounded Instance- and Label-dependent Label Noise. [<A HREF="https://arxiv.org/abs/1709.03768">PDF</A>] [<a href="https://github.com/tmllab/2020_ICML_Learning-with-bounded-instance-and-label-dependent-label-noise">CODE</a>]<br>
            J. Cheng, <b>T. Liu</b>, K. Rao, and D. Tao.<br>
            In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
            
            
            <li><p>
            Are Anchor Points Really Indispensable in Label-Noise Learning? [<A HREF="https://papers.nips.cc/paper/8908-are-anchor-points-really-indispensable-in-label-noise-learning.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2019_NeurIPS_T-Revision">CODE</A>]<br>
            X. Xia, <b>T. Liu</b>, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/">NeurIPS</a>, 2019.
            </p></li>
            
            
                        
            <li><p>
            Learning with Biased Complementary Labels. [<A HREF="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdf">PDF</A>] [<A HREF="code/Xiyu_eccv2018_backup.tar.gz">CODE</A>] [<font color="red">Oral</font>]<br>
            X. Yu, <b>T. Liu</b>, M. Gong, and D. Tao.<br>
            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
            </p></li>
            
            
                     
            <li><p>
            Classification with Noisy Labels by Importance Reweighting. [<A HREF="https://arxiv.org/pdf/1411.7718.pdf">PDF</A>] [<A HREF="https://github.com/tmllab/2015_PAMI_Classification-with-noisy-labels-by-importance-reweighting">CODE</A>]<br>
            <b>T. Liu</b> and D. Tao.<br>
            <b><i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i></b>, 38(3): 447-461, 2015.<br/>
            </p></li>
            
            <li> Talk: <A href="https://www.youtube.com/watch?v=iDWdKtbDw68" target="_blank">Learning with noisy labels</a> <br>
            <iframe width="227" height="140" src="https://www.youtube.com/embed/iDWdKtbDw68" frameborder="0" allowfullscreen></iframe></li>
            
            <!--             <li>Talk: <A href="https://www.bilibili.com/video/BV18g411x78d" target="_blank">Learning with noisy labels (in Chinese; long version)</a> <br>
            <iframe src="//player.bilibili.com/player.html?aid=519668159&bvid=BV18g411x78d&cid=950237695&page=1" frameborder="0" allowfullscreen="true"> </iframe>  </li> -->
            <!--     <iframe src="//player.bilibili.com/player.html?aid=519668159&bvid=BV18g411x78d&cid=950237695&page=1" scrolling="no" border="0" frameborder="0" framespacing="0" allowfullscreen> </iframe>  </li>                   -->
            </ul>
            </div>
<!--     <ul>
    <li> Talk: Learning with noisy labels <br>
    <iframe width="227" height="140" src="https://www.youtube.com/watch?v=iDWdKtbDw68" frameborder="0" allowfullscreen></iframe></li>
    <li> Talk: Learning with noisy labels (Chinese) <br>
    <iframe width="227" height="140" src="https://www.bilibili.com/video/BV18g411x78d" frameborder="0" allowfullscreen></iframe></li>
</ul> -->
     
      <div>
    <h2><a name="news"></a>Selected Publications on Adversarial Learning</h2>
          <ul>
              
              
            <li><p>
            Phase-aware Adversarial Defense for Improving Adversarial Robustness. [<A href="https://proceedings.mlr.press/v202/zhou23m/zhou23m.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_PAD">CODE</a>]<br>
            D. Zhou, N. Wang, H. Yang, X. Gao, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
            </p></li>             
                       
            <li><p>
            Eliminating Adversarial Noise via Information Discard and Robust Representation Restoration. [<A href="https://proceedings.mlr.press/v202/zhou23b/zhou23b.pdf">PDF</A>] [<a href="https://github.com/tmllab/2023_ICML_DIR">CODE</a>]<br>
            D. Zhou, Y. Chen, N. Wang, D. Liu, X. Gao, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2023"> ICML</a>, 2023.
            </p></li>

              
            <li><p>
            Modeling Adversarial Noise for Adversarial Defense. [<A href="https://arxiv.org/abs/2109.09901">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_MAN">CODE</a>]<br>
            D. Zhou, N. Wang, B. Han, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
            </p></li>
              
            <li><p>
            Improving Adversarial Robustness via Mutual Information Estimation. [<A href="https://proceedings.mlr.press/v162/zhou22j/zhou22j.pdf">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_MIAT">CODE</a>]<br>
            D. Zhou, N. Wang, X. Gao, B. Han, X. Wang, Y. Zhan, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
            </p></li>
    
                       
            <li><p>
            Understanding Robust Overfitting of Adversarial Training and Beyond. [<A href="https://arxiv.org/pdf/2206.08675.pdf">PDF</A>] [<a href="https://github.com/tmllab/2022_ICML_Understanding-Robust-Overfitting">CODE</a>]<br>
            C. Yu, B. Han, L. Shen, J. Yu, C. Gong, M. Gong, and <b>T. Liu</b>.<br>
            In <a href="https://icml.cc/Conferences/2022"> ICML</a>, 2022.
            </p></li>
              
           <li><p>
           Adversarial Robustness Through the Lens of Causality. [<A HREF="https://openreview.net/forum?id=cZAi1yWpiXQ&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [<a href="https://github.com/YonggangZhangUSTC/CausalAdv">CODE</a>] <br>
           Y. Zhang, M. Gong, <b>T. Liu</b>, G. Niu, X. Tian, B. Han, B. Schölkopf, and K. Zhang<br>
           In <a href="https://iclr.cc/"> ICLR</a>, 2022.
           </p></li>
              
        <li><p>
       Removing Adversarial Noise in Class Activation Feature Space. [<A HREF="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Removing_Adversarial_Noise_in_Class_Activation_Feature_Space_ICCV_2021_paper.pdf">PDF</A>] [<a href="https://github.com/tmllab/2021_ICCV_CAFD">CODE</a>]<br>
       D. Zhou, N. Wang, C. Peng, X. Gao, X. Wang, J. Yu, <b>T. Liu</b><br>
       In <a href="http://iccv2021.thecvf.com/"> ICCV</a>, 2021.
       </p></li>  
              
      <li><p>
       Towards Defending against Adversarial Examples via Attack-Invariant Features. [<A HREF="https://arxiv.org/pdf/2106.05036.pdf">PDF</A>] [<a href="https://github.com/tmllab/2021_ICML_ARN">CODE</a>]<br>
       D. Zhou, <b>T. Liu</b>, B. Han, N. Wang, C. Peng, and X. Gao <br>
       In <a href="https://icml.cc/Conferences/2021"> ICML</a>, 2021.
       </p></li>     
              
              
          </ul>
</div>
        

<!--         
          <div>
    <h2><a name="news"></a>Selected Publications on Causal Representation Learning</h2>
          <ul>
              
           <li><p>
           Adversarial Robustness Through the Lens of Causality. [<A HREF="https://openreview.net/forum?id=cZAi1yWpiXQ&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions)">PDF</A>] [CODE] <br>
           Y. Zhang, M. Gong, <b>T. Liu</b>, G. Niu, X. Tian, B. Han, B. Schölkopf, and K. Zhang<br>
           In <a href="https://iclr.cc/"> ICLR</a>, 2022.
           </p></li>
              
           <li><p>
           Fair Classification with Instance-dependent Label Noise. [<A HREF="https://openreview.net/forum?id=s-pcpETLpY">PDF</A>] <br>
           S. Wu, M. Gong, B. Han, Y. Liu, and <b>T. Liu</b><br>
           In <a href="https://www.cclear.cc/"> CLeaR</a>, 2022.
           </p></li>
             
        <li><p>
        Instance-Dependent Label-Noise Learning under Structural Causal Models. [<A HREF="https://arxiv.org/abs/2109.02986">PDF</A>] [<a href="https://github.com/a5507203/IDLN">CODE</a>]<br>
        Y. Yao, <b>T. Liu</b>, M. Gong, B. Han, G. Niu, and K. Zhang.<br>
        In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
        </p></li>
                   
              
          </ul> -->
</div>
    
    
    

    
    <div>
    <h2><a name="news"></a>Selected Publications on Transfer Learning</h2>
          <ul>
              
         
<!--                   <li><p>
        Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation.[<A HREF="https://ieeexplore.ieee.org/document/9204804">Paper</A>]<br>
       X. Yang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
        </p></li>   -->
              
         <li><p>
        Confident-Anchor-Induced Multi-Source-Free Domain Adaptation. [<A HREF="https://papers.nips.cc/paper/2021/file/168908dd3227b8358eababa07fcaf091-Paper.pdf">PDF</A>] [<a href="https://github.com/Learning-group123/CAiDA">CODE</a>]<br>
        J. Dong, Z. Fang, A. Liu, G. Sun, and <b>T. Liu</b>.<br>
        In <a href="https://nips.cc/"> NeurIPS</a>, 2021.
        </p></li>
        
              
              
        <li><p>
        Domain Generalization via Entropy Regularization. [<A HREF="https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf">PDF</A>] [<a href="https://github.com/sshan-zhao/DG_via_ER">CODE</a>]<br>
        S. Zhao, M. Gong, <b>T. Liu</b>,  H. Fu, and D. Tao.<br>
        In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
        </p></li>
              
        
<!--             <li><p>
        Label-Noise Robust Domain Adaptation.<br>
        X. Yu, <b>T. Liu</b>, M. Gong, K. Zhang, K. Batmanghelich, and D. Tao.<br>
         In <a href="https://icml.cc/"> ICML</a>, 2020.
        </p></li> -->
              
         <li><p>
        Transferring Knowledge Fragments for Learning Distance Metric from A Heterogeneous Domain. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8333749">Paper</A>] [<a href="https://github.com/yluopku/GB-HTDML">CODE</a>]<br>
        Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(4): 1013-1026, 2019.<br/>
        </p></li>
        
              
        <li><p>
        LTF: A Label Transformation Framework for Correcting Label Shift. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf">PDF</A>] [<a href="https://github.com/CR-Gjx/LTF-Label-Transformation-Framework">CODE</a>]<br>
        J. Guo, M. Gong, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
         In <a href="https://icml.cc/"> ICML</a>, 2020.
        </p></li>
              
        <li><p>
        Deep Domain Generalization via Conditional Invariant Adversarial Networks. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ya_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdf">PDF</A>] [<a href="http://staff.ustc.edu.cn/~xinmei/publications_pdf/2018/code-YaLi.zip">CODE</a>]<br>
        Y. Li, X. Tian, M. Gong, Y. Liu, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
        In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
        </p></li>
              
        <li><p>
        Understanding How Feature Structure Transfers in Transfer Learning. [<A HREF="https://www.ijcai.org/Proceedings/2017/0329.pdf">PDF</A>]<br>
        <b>T. Liu</b>, Q. Yang, and D. Tao.<br>
        In <a href="https://ijcai-17.org/"> IJCAI</a>, 2017.
        </p></li>

        <li><p>
        Domain Adaptation with Conditional Transferable Components. [<A HREF="http://proceedings.mlr.press/v48/gong16.pdf">PDF</A>] [<A HREF="code/CTC.zip">CODE</A>]<br>
        M. Gong, K. Zhang, <b>T. Liu</b>, D. Tao, C. Glymour, and B. Schölkopf.<br>
        In <a href="http://icml.cc/2016/"> ICML</a></i>, 2106.
        </p></li>
              
              
          </ul>
</div>
    
    

    
    <div>
    <h2><a name="news"></a>Selected Publications on Statistical (Deep) Learning Theory</h2>
          <ul>
        <li><p>
        On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes Optimal Classifier. [<A HREF="https://arxiv.org/abs/1802.03688">PDF</A>]<br>
        J. Zhang, <b>T. Liu</b>, and D. Tao.<br>
        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, accepted 2021.<br/>
        </p></li>   
        
              
        <li><p>
        Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence. [<A HREF="https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf">PDF</A>]<br>
        F. He, <b>T. Liu</b>, and D. Tao.<br>
        In <a href="https://nips.cc/">NeurIPS</a></i>, 2019.
        </p></li>
    
    
        <li><p>
        Algorithmic Stability and Hypothesis Complexity. [<A HREF="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">PDF</A>]<br>
        <b>T. Liu</b>, G. Lugosi, G. Neu and D. Tao.<br>
        In <a href="https://2017.icml.cc/"> ICML </a>, 2017.
        </p></li>
           

              
        <li><p>
        Algorithm-Dependent Generalization Bounds for Multi-Task Learning. [<A HREF="https://ieeexplore.ieee.org/document/7437460">Paper</A>]<br>
        <b>T. Liu</b>, D. Tao, M. Song, and S. J. Maybank.<br>
        <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 39(2): 227-241, 2017.<br/>
        </p></li>
    

              
              
          </ul>
See more publications <a href="publications.html">here</a>.
</div>



    
 <div>
<h2><hr><a name="sponsors"></a>Sponsors</h2>
     <p>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="arc sponsor.png" alt="Australian Research Council" width="200" height="50"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="usyd sponsor.png" alt="Usyd" width="150" height="50"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="CVI.jpeg" alt="CVI" width="150" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="CPA.png" alt="CPA" width="150" height="80"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="Meituan_English_Logo.png" alt="Meituan" width="150" height="40"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="logo_NSSN.png" alt="NSSN" width="150" height="50"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="logo-intelicare.png" alt="InteliCare" width="150" height="70"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="logo-ZhanDa.jpeg" alt="ZhanDa" width="150" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="jd.com.jpeg" alt="JD" width="125" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="Riken-aip.jpeg" alt="RIKEN" width="170" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="google-logo.png" alt="google" width="150" height="50"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="oppologo.png" alt="OPPO" width="150" height="50"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="mbzuai_logo.png" alt="MBZUAI" width="245" height="61"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="NetEase.png" alt="NetEase" width="140" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="pawsey.png" alt="NetEase" width="170" height="90"/>
             <img class="center" style="margin: 4px 4px 4px 4px;" src="nci.png" alt="NetEase" width="150" height="90"/>


</p>
</div>
    
<div>

  <h2 style="font-family: Helvetica,Arial,sans-serif;"><o:p>&nbsp;</o:p></h2>
  <p>
<!--         Last Update: 5/2019.<br> -->
<script src="//t1.extreme-dm.com/f.js" id="eXF-tliu9526-0" async defer></script>


</p>
</div>

</td>
</tr>
</table>
</body>
</html>
